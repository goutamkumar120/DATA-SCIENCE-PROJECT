{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fake News Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goutamkumar120/DATA-SCIENCE-PROJECT/blob/main/Fake_News_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkFyxhE_sfzL",
        "outputId": "7ca48d70-8f01-411f-a915-9020f851d421"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDLWpwhcA6CL",
        "outputId": "8323f0d0-ae0b-48ee-d598-4c39f5952a04"
      },
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import re\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.svm import SVC \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from xgboost import XGBClassifier\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.preprocessing import normalize\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc_gcfRdspvJ"
      },
      "source": [
        "train = pd.read_csv('/content/gdrive/MyDrive/train.csv')\n",
        "test = pd.read_csv('/content/gdrive/MyDrive/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "eZ38tERE0Wi7",
        "outputId": "1c37d9cb-4599-4c9f-bbf4-f7706290dc72"
      },
      "source": [
        "train.head()\n",
        "\n",
        "## Label 1 is unreliable and 0 is reliable"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>Darrell Lucus</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
              "      <td>Daniel J. Flynn</td>\n",
              "      <td>Ever get the feeling your life circles the rou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Why the Truth Might Get You Fired</td>\n",
              "      <td>Consortiumnews.com</td>\n",
              "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
              "      <td>Jessica Purkiss</td>\n",
              "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
              "      <td>Howard Portnoy</td>\n",
              "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ... label\n",
              "0   0  ...     1\n",
              "1   1  ...     0\n",
              "2   2  ...     1\n",
              "3   3  ...     1\n",
              "4   4  ...     1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "jfI89adi0eBZ",
        "outputId": "3f9fb7d0-2a3c-44d3-bcec-adeb5f5622df"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20800</td>\n",
              "      <td>Specter of Trump Loosens Tongues, if Not Purse...</td>\n",
              "      <td>David Streitfeld</td>\n",
              "      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20801</td>\n",
              "      <td>Russian warships ready to strike terrorists ne...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Russian warships ready to strike terrorists ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20802</td>\n",
              "      <td>#NoDAPL: Native American Leaders Vow to Stay A...</td>\n",
              "      <td>Common Dreams</td>\n",
              "      <td>Videos #NoDAPL: Native American Leaders Vow to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20803</td>\n",
              "      <td>Tim Tebow Will Attempt Another Comeback, This ...</td>\n",
              "      <td>Daniel Victor</td>\n",
              "      <td>If at first you don’t succeed, try a different...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20804</td>\n",
              "      <td>Keiser Report: Meme Wars (E995)</td>\n",
              "      <td>Truth Broadcast Network</td>\n",
              "      <td>42 mins ago 1 Views 0 Comments 0 Likes 'For th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ...                                               text\n",
              "0  20800  ...  PALO ALTO, Calif.  —   After years of scorning...\n",
              "1  20801  ...  Russian warships ready to strike terrorists ne...\n",
              "2  20802  ...  Videos #NoDAPL: Native American Leaders Vow to...\n",
              "3  20803  ...  If at first you don’t succeed, try a different...\n",
              "4  20804  ...  42 mins ago 1 Views 0 Comments 0 Likes 'For th...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHef8EaZ0fUV",
        "outputId": "45a713b8-27e6-471d-9f38-4d72b9e17626"
      },
      "source": [
        "train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20800 entries, 0 to 20799\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   id      20800 non-null  int64 \n",
            " 1   title   20242 non-null  object\n",
            " 2   author  18843 non-null  object\n",
            " 3   text    20761 non-null  object\n",
            " 4   label   20800 non-null  int64 \n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 812.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QepvfxHYuvV4",
        "outputId": "e19ae48e-876a-49be-824b-1adc0e4c4838"
      },
      "source": [
        "test.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5200 entries, 0 to 5199\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   id      5200 non-null   int64 \n",
            " 1   title   5078 non-null   object\n",
            " 2   author  4697 non-null   object\n",
            " 3   text    5193 non-null   object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 162.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRRk353C0onb"
      },
      "source": [
        "train.fillna(' ', inplace = True)\n",
        "test.fillna(' ', inplace = True)\n",
        "\n",
        "## All the null values were filled with spaces."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "VMeFOqpy0wwf",
        "outputId": "8d0b7de7-18e3-4cda-dad6-8a8f4a9360e6"
      },
      "source": [
        "train_new = pd.DataFrame({'Author' : train[train['label'] == 1]['author'].value_counts().head(20).index, 'Quantities' : train[train['label'] == 1]['author'].value_counts().head(20)})\n",
        "unreliable_plot = train_new.plot(kind = 'bar', x = 'Author', y = 'Quantities')\n",
        "unreliable_plot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5eb3521a50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "tPUZmP_n1trr",
        "outputId": "78af0f1e-46f1-4293-9d99-56f594313fc5"
      },
      "source": [
        "train_new_reliable = pd.DataFrame({'Author' : train[train['label'] == 0]['author'].value_counts().head(20).index, 'Quantities' : train[train['label'] == 0]['author'].value_counts().head(20)})\n",
        "reliable_plot = train_new_reliable.plot(kind = 'bar', x = 'Author', y = 'Quantities')\n",
        "reliable_plot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5eb370ecd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3E7eCmO2AJ6"
      },
      "source": [
        "unreliable_count = len(train[train['label'] == 1])\n",
        "reliable_count = len(train[train['label'] == 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "M-wun4Im2OyS",
        "outputId": "7d1fcc91-0dd7-40b7-c8ee-e5fc22c19ddc"
      },
      "source": [
        "x = np.array([unreliable_count, reliable_count])\n",
        "mylabels = ['Unreliable', 'Reliable']\n",
        "plt.pie(x, labels = mylabels, autopct = '%.3f')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BPVh-ldbbWW"
      },
      "source": [
        "train['total'] = train['title'] + train['author']\n",
        "test['total'] = test['title'] + test['author']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1NRr1IH3R7e"
      },
      "source": [
        "stemmer = PorterStemmer()\n",
        "\n",
        "def porterstemmer(text):\n",
        "    review = re.sub('[^a-zA-Z]', ' ', text)\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    review = [stemmer.stem(words) for words in review if words not in stopwords.words('english') and words.isalpha()]\n",
        "    review = ' '.join(review)\n",
        "    return review\n",
        "\n",
        "\n",
        "## This helps us to remove the stopwords and also to trim the important words and this is the first data preprocessing step."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGEfenchctT8"
      },
      "source": [
        "train['clean_total'] = train['total'].apply(porterstemmer)\n",
        "test['clean_total'] = test['total'].apply(porterstemmer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFF4Hek2ToDc"
      },
      "source": [
        "df_train = train[['title', 'label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjZF5eJjXbq7"
      },
      "source": [
        "unreliable_title = df_train[df_train['label'] == 1]['title']\n",
        "reliable_title = df_train[df_train['label'] == 0]['title']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeFa4qBSYOlp"
      },
      "source": [
        "common_words_reliable = pd.Series(' '.join([str(i) for i in reliable_title]).split()).value_counts().head(30).index\n",
        "common_words_unreliable = pd.Series(' '.join([str(i) for i in unreliable_title]).split()).value_counts().head(30).index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ5tA27RZG9w"
      },
      "source": [
        "common_words = set(common_words_reliable).intersection(common_words_unreliable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLWy9YC7ZcqU"
      },
      "source": [
        "def text_cleaning(data):\n",
        "  review = [i for i in data.split() if i not in common_words]\n",
        "  return review\n",
        "\n",
        "## All the common words in the first 30 entries were removed from the data."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFj-YJU8aEtC"
      },
      "source": [
        "train['new_total'] = train['clean_total'].apply(text_cleaning)\n",
        "test['new_total'] = test['clean_total'].apply(text_cleaning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AR93gLYkaKnn",
        "outputId": "10ed1413-bd6e-45c3-f76e-14528baf8a14"
      },
      "source": [
        "np.max(train['new_total'].apply(lambda x : len(x)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-94D_c9gGfA"
      },
      "source": [
        "train = train.drop(columns = ['text', 'id'])\n",
        "test = test.drop(columns = ['text', 'id'])\n",
        "\n",
        "\n",
        "## Unnecessary columns were removed."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7F19GeoLpHv"
      },
      "source": [
        "## Function to do produce a tf-idf frequency matrix\n",
        "corpus_vectorizer = TfidfVectorizer(norm = None)\n",
        "\n",
        "def tf_idf_matrix(corp):\n",
        "  tf_idf_scores = corpus_vectorizer.fit_transform(corp)\n",
        "  feature_names = corpus_vectorizer.get_feature_names()\n",
        "  df = pd.DataFrame(tf_idf_scores.T.todense(), index = feature_names, columns = [i for i in range(1, len(corp)+1)])\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N137pZWLNRkD"
      },
      "source": [
        "document = train['clean_total']\n",
        "df = tf_idf_matrix(document)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfEAxzo5LMve"
      },
      "source": [
        "lst = []\n",
        "for k in range(1, 20801): \n",
        "  x = df[k].where(df[k].values > 0.0)\n",
        "  x.fillna(0.0, inplace = True)\n",
        "  y = []\n",
        "  for i in x:\n",
        "    if i > 0.0:\n",
        "      y.append(i)\n",
        "\n",
        "  lst.append(y)\n",
        "\n",
        "\n",
        "## From the sparse tf-idf matrix only the values that were not 0 were taken."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGkzRrP0khI8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "63759c6e-d6c1-4ce1-e943-d4984bb9296f"
      },
      "source": [
        "main_df = pd.DataFrame(lst, columns = [i for i in range(1,47)])\n",
        "main_df.fillna(0.0, inplace = True)\n",
        "main_df\n",
        "\n",
        "## And the main dataframe was formed from those values and even though this matrix is sparse it is almost 500 times smaller than the size of the previous one."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.368045</td>\n",
              "      <td>8.640171</td>\n",
              "      <td>5.849006</td>\n",
              "      <td>6.357789</td>\n",
              "      <td>5.487435</td>\n",
              "      <td>5.174435</td>\n",
              "      <td>10.249609</td>\n",
              "      <td>7.723881</td>\n",
              "      <td>6.899705</td>\n",
              "      <td>8.544861</td>\n",
              "      <td>6.044917</td>\n",
              "      <td>6.783873</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.880161</td>\n",
              "      <td>7.387408</td>\n",
              "      <td>7.646919</td>\n",
              "      <td>3.844381</td>\n",
              "      <td>14.272188</td>\n",
              "      <td>3.842729</td>\n",
              "      <td>6.030101</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.758607</td>\n",
              "      <td>10.249609</td>\n",
              "      <td>5.165104</td>\n",
              "      <td>7.331838</td>\n",
              "      <td>6.548307</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.359237</td>\n",
              "      <td>7.010931</td>\n",
              "      <td>10.249609</td>\n",
              "      <td>5.187014</td>\n",
              "      <td>10.249609</td>\n",
              "      <td>7.575461</td>\n",
              "      <td>4.835733</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10.249609</td>\n",
              "      <td>6.037482</td>\n",
              "      <td>8.996846</td>\n",
              "      <td>7.723881</td>\n",
              "      <td>7.092609</td>\n",
              "      <td>7.136094</td>\n",
              "      <td>7.998317</td>\n",
              "      <td>6.476848</td>\n",
              "      <td>10.249609</td>\n",
              "      <td>12.060203</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20795</th>\n",
              "      <td>6.399462</td>\n",
              "      <td>5.760973</td>\n",
              "      <td>7.071555</td>\n",
              "      <td>8.377807</td>\n",
              "      <td>8.303699</td>\n",
              "      <td>9.333318</td>\n",
              "      <td>2.769181</td>\n",
              "      <td>5.190184</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20796</th>\n",
              "      <td>7.947024</td>\n",
              "      <td>9.556462</td>\n",
              "      <td>2.124274</td>\n",
              "      <td>8.745532</td>\n",
              "      <td>8.745532</td>\n",
              "      <td>8.544861</td>\n",
              "      <td>7.508769</td>\n",
              "      <td>2.197950</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20797</th>\n",
              "      <td>7.851714</td>\n",
              "      <td>8.109543</td>\n",
              "      <td>8.863315</td>\n",
              "      <td>5.595649</td>\n",
              "      <td>5.760973</td>\n",
              "      <td>5.899331</td>\n",
              "      <td>9.556462</td>\n",
              "      <td>7.807262</td>\n",
              "      <td>2.124274</td>\n",
              "      <td>6.972464</td>\n",
              "      <td>7.205087</td>\n",
              "      <td>6.560730</td>\n",
              "      <td>8.544861</td>\n",
              "      <td>5.297309</td>\n",
              "      <td>2.19795</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20798</th>\n",
              "      <td>6.511940</td>\n",
              "      <td>10.249609</td>\n",
              "      <td>8.544861</td>\n",
              "      <td>6.799622</td>\n",
              "      <td>6.723249</td>\n",
              "      <td>9.333318</td>\n",
              "      <td>4.750394</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20799</th>\n",
              "      <td>10.249609</td>\n",
              "      <td>6.288796</td>\n",
              "      <td>7.764703</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20800 rows × 46 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              1          2          3         4   ...   43   44   45   46\n",
              "0       6.368045   8.640171   5.849006  6.357789  ...  0.0  0.0  0.0  0.0\n",
              "1       5.880161   7.387408   7.646919  3.844381  ...  0.0  0.0  0.0  0.0\n",
              "2       4.758607  10.249609   5.165104  7.331838  ...  0.0  0.0  0.0  0.0\n",
              "3       7.359237   7.010931  10.249609  5.187014  ...  0.0  0.0  0.0  0.0\n",
              "4      10.249609   6.037482   8.996846  7.723881  ...  0.0  0.0  0.0  0.0\n",
              "...          ...        ...        ...       ...  ...  ...  ...  ...  ...\n",
              "20795   6.399462   5.760973   7.071555  8.377807  ...  0.0  0.0  0.0  0.0\n",
              "20796   7.947024   9.556462   2.124274  8.745532  ...  0.0  0.0  0.0  0.0\n",
              "20797   7.851714   8.109543   8.863315  5.595649  ...  0.0  0.0  0.0  0.0\n",
              "20798   6.511940  10.249609   8.544861  6.799622  ...  0.0  0.0  0.0  0.0\n",
              "20799  10.249609   6.288796   7.764703  0.000000  ...  0.0  0.0  0.0  0.0\n",
              "\n",
              "[20800 rows x 46 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCFGWJGLuK61"
      },
      "source": [
        "And then the test and training accuracy was tested upon the dataset by using a KNeighborsClassifier, SVMs and Logistic Regression. Then all of them were tried on the test dataset to get the accuracies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQFI-pdOOWvA"
      },
      "source": [
        "X = main_df[0:].to_numpy()\n",
        "y = train.label.to_numpy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyaws4ZkPFhE"
      },
      "source": [
        "k_range = range(1, 21)\n",
        "scores_training = []\n",
        "scores_testing = []\n",
        "scores_precision = []\n",
        "for i in k_range:\n",
        "  knn = KNeighborsClassifier(n_neighbors = i)\n",
        "  knn.fit(X_train, y_train)\n",
        "  scores_training.append(knn.score(X_train, y_train))\n",
        "  scores_testing.append(knn.score(X_test, y_test))\n",
        "  scores_precision.append(precision_score(knn.predict(X_test), y_test))\n",
        "\n",
        "\n",
        "## This helps in picking the best value of k in KNeighborsClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Ui0oNSc0Rz87",
        "outputId": "712683e5-6ceb-45f7-89f2-495ff959a97f"
      },
      "source": [
        "plt.plot(k_range, scores_training, color = 'r', label = 'Training')\n",
        "plt.plot(k_range, scores_testing, color = 'g', label = 'Testing')\n",
        "plt.plot(k_range, scores_precision, color = 'b', label = 'Precision')\n",
        "plt.xlabel('Accuracy Scores')\n",
        "plt.ylabel('Range')\n",
        "plt.legend(loc = 'upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "egjtgerjSHMI",
        "outputId": "ed424d46-ee4f-4571-a5ff-21c81a74cc8a"
      },
      "source": [
        "knn_df = pd.DataFrame([scores_training, scores_testing, scores_precision], index = ['Training', 'Testing', 'Precision'])\n",
        "knn_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Training</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.855829</td>\n",
              "      <td>0.876142</td>\n",
              "      <td>0.828185</td>\n",
              "      <td>0.844050</td>\n",
              "      <td>0.814063</td>\n",
              "      <td>0.825901</td>\n",
              "      <td>0.803726</td>\n",
              "      <td>0.814603</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.809135</td>\n",
              "      <td>0.794471</td>\n",
              "      <td>0.803425</td>\n",
              "      <td>0.791106</td>\n",
              "      <td>0.795673</td>\n",
              "      <td>0.786238</td>\n",
              "      <td>0.792849</td>\n",
              "      <td>0.785036</td>\n",
              "      <td>0.789784</td>\n",
              "      <td>0.783474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Testing</th>\n",
              "      <td>0.748798</td>\n",
              "      <td>0.717308</td>\n",
              "      <td>0.758413</td>\n",
              "      <td>0.746154</td>\n",
              "      <td>0.766827</td>\n",
              "      <td>0.754567</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.755288</td>\n",
              "      <td>0.764904</td>\n",
              "      <td>0.752644</td>\n",
              "      <td>0.762981</td>\n",
              "      <td>0.756250</td>\n",
              "      <td>0.765385</td>\n",
              "      <td>0.761058</td>\n",
              "      <td>0.767548</td>\n",
              "      <td>0.761779</td>\n",
              "      <td>0.771394</td>\n",
              "      <td>0.761058</td>\n",
              "      <td>0.765144</td>\n",
              "      <td>0.761298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Precision</th>\n",
              "      <td>0.719631</td>\n",
              "      <td>0.545190</td>\n",
              "      <td>0.729835</td>\n",
              "      <td>0.624879</td>\n",
              "      <td>0.737609</td>\n",
              "      <td>0.656948</td>\n",
              "      <td>0.737123</td>\n",
              "      <td>0.669582</td>\n",
              "      <td>0.733236</td>\n",
              "      <td>0.672498</td>\n",
              "      <td>0.731778</td>\n",
              "      <td>0.681730</td>\n",
              "      <td>0.730807</td>\n",
              "      <td>0.689018</td>\n",
              "      <td>0.733722</td>\n",
              "      <td>0.693878</td>\n",
              "      <td>0.735666</td>\n",
              "      <td>0.692420</td>\n",
              "      <td>0.724490</td>\n",
              "      <td>0.688533</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0         1         2   ...        17        18        19\n",
              "Training   1.000000  0.855829  0.876142  ...  0.785036  0.789784  0.783474\n",
              "Testing    0.748798  0.717308  0.758413  ...  0.761058  0.765144  0.761298\n",
              "Precision  0.719631  0.545190  0.729835  ...  0.692420  0.724490  0.688533\n",
              "\n",
              "[3 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZ_NHpexp6DJ",
        "outputId": "0a86466e-1131-40de-b4af-b3d197ccd620"
      },
      "source": [
        "!pip install kneed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kneed\n",
            "  Downloading https://files.pythonhosted.org/packages/c3/6b/e130913aaaad1373060e259ab222ca2330672db696b297b082c3f3089fcc/kneed-0.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.7/dist-packages (from kneed) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from kneed) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from kneed) (1.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->kneed) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->kneed) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->kneed) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->kneed) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->kneed) (1.15.0)\n",
            "Installing collected packages: kneed\n",
            "Successfully installed kneed-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "2Nk2x_XjmnqW",
        "outputId": "f100def1-6939-4b23-e4f0-64039426da93"
      },
      "source": [
        "from kneed import KneeLocator\n",
        "\n",
        "kl = KneeLocator(x = range(1, 21), y = scores_training, curve = 'convex', direction = 'decreasing', S = 1, interp_method = 'polynomial')\n",
        "kl.plot_knee_normalized()\n",
        "print(kl.knee)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "YvK-mRR3qalz",
        "outputId": "b0224027-0f96-4c8e-bf65-4354787d2c98"
      },
      "source": [
        "kl = KneeLocator(x = range(1, 21), y = scores_precision, curve = 'convex', direction = 'decreasing', S = 1, interp_method = 'polynomial')\n",
        "kl.plot_knee_normalized()\n",
        "print(kl.knee)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pszncK2xVud5",
        "outputId": "108dd6eb-4302-4dd3-d665-11fdd4bb2aa0"
      },
      "source": [
        "param_grid = {'C' : [1, 10, 100],\n",
        "              'gamma' : [1, 0.1, 0.01],\n",
        "              'kernel' : ['rbf'],\n",
        "              'degree' : [3, 4, 5]}\n",
        "\n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 4)\n",
        "grid.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
            "[CV] C=1, degree=3, gamma=1, kernel=rbf ..............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .. C=1, degree=3, gamma=1, kernel=rbf, score=0.627, total= 1.0min\n",
            "[CV] C=1, degree=3, gamma=1, kernel=rbf ..............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.0min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .. C=1, degree=3, gamma=1, kernel=rbf, score=0.629, total=  59.4s\n",
            "[CV] C=1, degree=3, gamma=1, kernel=rbf ..............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.0min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .. C=1, degree=3, gamma=1, kernel=rbf, score=0.633, total=  59.2s\n",
            "[CV] C=1, degree=3, gamma=1, kernel=rbf ..............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  3.0min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .. C=1, degree=3, gamma=1, kernel=rbf, score=0.623, total=  59.3s\n",
            "[CV] C=1, degree=3, gamma=1, kernel=rbf ..............................\n",
            "[CV] .. C=1, degree=3, gamma=1, kernel=rbf, score=0.633, total= 1.0min\n",
            "[CV] C=1, degree=3, gamma=0.1, kernel=rbf ............................\n",
            "[CV]  C=1, degree=3, gamma=0.1, kernel=rbf, score=0.773, total=  40.1s\n",
            "[CV] C=1, degree=3, gamma=0.1, kernel=rbf ............................\n",
            "[CV]  C=1, degree=3, gamma=0.1, kernel=rbf, score=0.776, total=  40.3s\n",
            "[CV] C=1, degree=3, gamma=0.1, kernel=rbf ............................\n",
            "[CV]  C=1, degree=3, gamma=0.1, kernel=rbf, score=0.764, total=  50.4s\n",
            "[CV] C=1, degree=3, gamma=0.1, kernel=rbf ............................\n",
            "[CV]  C=1, degree=3, gamma=0.1, kernel=rbf, score=0.753, total=  40.9s\n",
            "[CV] C=1, degree=3, gamma=0.1, kernel=rbf ............................\n",
            "[CV]  C=1, degree=3, gamma=0.1, kernel=rbf, score=0.765, total=  40.5s\n",
            "[CV] C=1, degree=3, gamma=0.01, kernel=rbf ...........................\n",
            "[CV]  C=1, degree=3, gamma=0.01, kernel=rbf, score=0.768, total=  17.0s\n",
            "[CV] C=1, degree=3, gamma=0.01, kernel=rbf ...........................\n",
            "[CV]  C=1, degree=3, gamma=0.01, kernel=rbf, score=0.764, total=  16.8s\n",
            "[CV] C=1, degree=3, gamma=0.01, kernel=rbf ...........................\n",
            "[CV]  C=1, degree=3, gamma=0.01, kernel=rbf, score=0.754, total=  16.6s\n",
            "[CV] C=1, degree=3, gamma=0.01, kernel=rbf ...........................\n",
            "[CV]  C=1, degree=3, gamma=0.01, kernel=rbf, score=0.745, total=  16.5s\n",
            "[CV] C=1, degree=3, gamma=0.01, kernel=rbf ...........................\n",
            "[CV]  C=1, degree=3, gamma=0.01, kernel=rbf, score=0.766, total=  16.5s\n",
            "[CV] C=1, degree=4, gamma=1, kernel=rbf ..............................\n",
            "[CV] .. C=1, degree=4, gamma=1, kernel=rbf, score=0.627, total=  59.5s\n",
            "[CV] C=1, degree=4, gamma=1, kernel=rbf ..............................\n",
            "[CV] .. C=1, degree=4, gamma=1, kernel=rbf, score=0.629, total=  59.4s\n",
            "[CV] C=1, degree=4, gamma=1, kernel=rbf ..............................\n",
            "[CV] .. C=1, degree=4, gamma=1, kernel=rbf, score=0.633, total=  59.2s\n",
            "[CV] C=1, degree=4, gamma=1, kernel=rbf ..............................\n",
            "[CV] .. C=1, degree=4, gamma=1, kernel=rbf, score=0.623, total=  59.7s\n",
            "[CV] C=1, degree=4, gamma=1, kernel=rbf ..............................\n",
            "[CV] .. C=1, degree=4, gamma=1, kernel=rbf, score=0.633, total=  58.7s\n",
            "[CV] C=1, degree=4, gamma=0.1, kernel=rbf ............................\n",
            "[CV]  C=1, degree=4, gamma=0.1, kernel=rbf, score=0.773, total=  39.1s\n",
            "[CV] C=1, degree=4, gamma=0.1, kernel=rbf ............................\n",
            "[CV]  C=1, degree=4, gamma=0.1, kernel=rbf, score=0.776, total=  40.3s\n",
            "[CV] C=1, degree=4, gamma=0.1, kernel=rbf ............................\n",
            "[CV]  C=1, degree=4, gamma=0.1, kernel=rbf, score=0.764, total=  48.8s\n",
            "[CV] C=1, degree=4, gamma=0.1, kernel=rbf ............................\n",
            "[CV]  C=1, degree=4, gamma=0.1, kernel=rbf, score=0.753, total=  39.9s\n",
            "[CV] C=1, degree=4, gamma=0.1, kernel=rbf ............................\n",
            "[CV]  C=1, degree=4, gamma=0.1, kernel=rbf, score=0.765, total=  40.1s\n",
            "[CV] C=1, degree=4, gamma=0.01, kernel=rbf ...........................\n",
            "[CV]  C=1, degree=4, gamma=0.01, kernel=rbf, score=0.768, total=  16.9s\n",
            "[CV] C=1, degree=4, gamma=0.01, kernel=rbf ...........................\n",
            "[CV]  C=1, degree=4, gamma=0.01, kernel=rbf, score=0.764, total=  16.7s\n",
            "[CV] C=1, degree=4, gamma=0.01, kernel=rbf ...........................\n",
            "[CV]  C=1, degree=4, gamma=0.01, kernel=rbf, score=0.754, total=  16.5s\n",
            "[CV] C=1, degree=4, gamma=0.01, kernel=rbf ...........................\n",
            "[CV]  C=1, degree=4, gamma=0.01, kernel=rbf, score=0.745, total=  16.3s\n",
            "[CV] C=1, degree=4, gamma=0.01, kernel=rbf ...........................\n",
            "[CV]  C=1, degree=4, gamma=0.01, kernel=rbf, score=0.766, total=  16.4s\n",
            "[CV] C=1, degree=5, gamma=1, kernel=rbf ..............................\n",
            "[CV] .. C=1, degree=5, gamma=1, kernel=rbf, score=0.627, total= 1.0min\n",
            "[CV] C=1, degree=5, gamma=1, kernel=rbf ..............................\n",
            "[CV] .. C=1, degree=5, gamma=1, kernel=rbf, score=0.629, total= 1.0min\n",
            "[CV] C=1, degree=5, gamma=1, kernel=rbf ..............................\n",
            "[CV] .. C=1, degree=5, gamma=1, kernel=rbf, score=0.633, total=  59.3s\n",
            "[CV] C=1, degree=5, gamma=1, kernel=rbf ..............................\n",
            "[CV] .. C=1, degree=5, gamma=1, kernel=rbf, score=0.623, total=  59.7s\n",
            "[CV] C=1, degree=5, gamma=1, kernel=rbf ..............................\n",
            "[CV] .. C=1, degree=5, gamma=1, kernel=rbf, score=0.633, total=  58.9s\n",
            "[CV] C=1, degree=5, gamma=0.1, kernel=rbf ............................\n",
            "[CV]  C=1, degree=5, gamma=0.1, kernel=rbf, score=0.773, total=  39.5s\n",
            "[CV] C=1, degree=5, gamma=0.1, kernel=rbf ............................\n",
            "[CV]  C=1, degree=5, gamma=0.1, kernel=rbf, score=0.776, total=  40.6s\n",
            "[CV] C=1, degree=5, gamma=0.1, kernel=rbf ............................\n",
            "[CV]  C=1, degree=5, gamma=0.1, kernel=rbf, score=0.764, total=  48.5s\n",
            "[CV] C=1, degree=5, gamma=0.1, kernel=rbf ............................\n",
            "[CV]  C=1, degree=5, gamma=0.1, kernel=rbf, score=0.753, total=  40.6s\n",
            "[CV] C=1, degree=5, gamma=0.1, kernel=rbf ............................\n",
            "[CV]  C=1, degree=5, gamma=0.1, kernel=rbf, score=0.765, total=  39.5s\n",
            "[CV] C=1, degree=5, gamma=0.01, kernel=rbf ...........................\n",
            "[CV]  C=1, degree=5, gamma=0.01, kernel=rbf, score=0.768, total=  16.7s\n",
            "[CV] C=1, degree=5, gamma=0.01, kernel=rbf ...........................\n",
            "[CV]  C=1, degree=5, gamma=0.01, kernel=rbf, score=0.764, total=  16.8s\n",
            "[CV] C=1, degree=5, gamma=0.01, kernel=rbf ...........................\n",
            "[CV]  C=1, degree=5, gamma=0.01, kernel=rbf, score=0.754, total=  16.5s\n",
            "[CV] C=1, degree=5, gamma=0.01, kernel=rbf ...........................\n",
            "[CV]  C=1, degree=5, gamma=0.01, kernel=rbf, score=0.745, total=  16.6s\n",
            "[CV] C=1, degree=5, gamma=0.01, kernel=rbf ...........................\n",
            "[CV]  C=1, degree=5, gamma=0.01, kernel=rbf, score=0.766, total=  16.7s\n",
            "[CV] C=10, degree=3, gamma=1, kernel=rbf .............................\n",
            "[CV] . C=10, degree=3, gamma=1, kernel=rbf, score=0.636, total= 1.4min\n",
            "[CV] C=10, degree=3, gamma=1, kernel=rbf .............................\n",
            "[CV] . C=10, degree=3, gamma=1, kernel=rbf, score=0.640, total= 1.4min\n",
            "[CV] C=10, degree=3, gamma=1, kernel=rbf .............................\n",
            "[CV] . C=10, degree=3, gamma=1, kernel=rbf, score=0.644, total= 1.5min\n",
            "[CV] C=10, degree=3, gamma=1, kernel=rbf .............................\n",
            "[CV] . C=10, degree=3, gamma=1, kernel=rbf, score=0.636, total= 1.4min\n",
            "[CV] C=10, degree=3, gamma=1, kernel=rbf .............................\n",
            "[CV] . C=10, degree=3, gamma=1, kernel=rbf, score=0.638, total= 1.4min\n",
            "[CV] C=10, degree=3, gamma=0.1, kernel=rbf ...........................\n",
            "[CV]  C=10, degree=3, gamma=0.1, kernel=rbf, score=0.749, total=  56.6s\n",
            "[CV] C=10, degree=3, gamma=0.1, kernel=rbf ...........................\n",
            "[CV]  C=10, degree=3, gamma=0.1, kernel=rbf, score=0.761, total=  56.7s\n",
            "[CV] C=10, degree=3, gamma=0.1, kernel=rbf ...........................\n",
            "[CV]  C=10, degree=3, gamma=0.1, kernel=rbf, score=0.751, total=  56.7s\n",
            "[CV] C=10, degree=3, gamma=0.1, kernel=rbf ...........................\n",
            "[CV]  C=10, degree=3, gamma=0.1, kernel=rbf, score=0.730, total=  55.4s\n",
            "[CV] C=10, degree=3, gamma=0.1, kernel=rbf ...........................\n",
            "[CV]  C=10, degree=3, gamma=0.1, kernel=rbf, score=0.747, total=  56.4s\n",
            "[CV] C=10, degree=3, gamma=0.01, kernel=rbf ..........................\n",
            "[CV]  C=10, degree=3, gamma=0.01, kernel=rbf, score=0.789, total=  20.4s\n",
            "[CV] C=10, degree=3, gamma=0.01, kernel=rbf ..........................\n",
            "[CV]  C=10, degree=3, gamma=0.01, kernel=rbf, score=0.788, total=  20.3s\n",
            "[CV] C=10, degree=3, gamma=0.01, kernel=rbf ..........................\n",
            "[CV]  C=10, degree=3, gamma=0.01, kernel=rbf, score=0.776, total=  20.1s\n",
            "[CV] C=10, degree=3, gamma=0.01, kernel=rbf ..........................\n",
            "[CV]  C=10, degree=3, gamma=0.01, kernel=rbf, score=0.760, total=  19.6s\n",
            "[CV] C=10, degree=3, gamma=0.01, kernel=rbf ..........................\n",
            "[CV]  C=10, degree=3, gamma=0.01, kernel=rbf, score=0.784, total=  20.3s\n",
            "[CV] C=10, degree=4, gamma=1, kernel=rbf .............................\n",
            "[CV] . C=10, degree=4, gamma=1, kernel=rbf, score=0.636, total= 1.4min\n",
            "[CV] C=10, degree=4, gamma=1, kernel=rbf .............................\n",
            "[CV] . C=10, degree=4, gamma=1, kernel=rbf, score=0.640, total= 1.4min\n",
            "[CV] C=10, degree=4, gamma=1, kernel=rbf .............................\n",
            "[CV] . C=10, degree=4, gamma=1, kernel=rbf, score=0.644, total= 1.5min\n",
            "[CV] C=10, degree=4, gamma=1, kernel=rbf .............................\n",
            "[CV] . C=10, degree=4, gamma=1, kernel=rbf, score=0.636, total= 1.4min\n",
            "[CV] C=10, degree=4, gamma=1, kernel=rbf .............................\n",
            "[CV] . C=10, degree=4, gamma=1, kernel=rbf, score=0.638, total= 1.4min\n",
            "[CV] C=10, degree=4, gamma=0.1, kernel=rbf ...........................\n",
            "[CV]  C=10, degree=4, gamma=0.1, kernel=rbf, score=0.749, total=  56.9s\n",
            "[CV] C=10, degree=4, gamma=0.1, kernel=rbf ...........................\n",
            "[CV]  C=10, degree=4, gamma=0.1, kernel=rbf, score=0.761, total=  56.8s\n",
            "[CV] C=10, degree=4, gamma=0.1, kernel=rbf ...........................\n",
            "[CV]  C=10, degree=4, gamma=0.1, kernel=rbf, score=0.751, total=  56.9s\n",
            "[CV] C=10, degree=4, gamma=0.1, kernel=rbf ...........................\n",
            "[CV]  C=10, degree=4, gamma=0.1, kernel=rbf, score=0.730, total=  55.7s\n",
            "[CV] C=10, degree=4, gamma=0.1, kernel=rbf ...........................\n",
            "[CV]  C=10, degree=4, gamma=0.1, kernel=rbf, score=0.747, total=  56.7s\n",
            "[CV] C=10, degree=4, gamma=0.01, kernel=rbf ..........................\n",
            "[CV]  C=10, degree=4, gamma=0.01, kernel=rbf, score=0.789, total=  20.5s\n",
            "[CV] C=10, degree=4, gamma=0.01, kernel=rbf ..........................\n",
            "[CV]  C=10, degree=4, gamma=0.01, kernel=rbf, score=0.788, total=  20.4s\n",
            "[CV] C=10, degree=4, gamma=0.01, kernel=rbf ..........................\n",
            "[CV]  C=10, degree=4, gamma=0.01, kernel=rbf, score=0.776, total=  20.1s\n",
            "[CV] C=10, degree=4, gamma=0.01, kernel=rbf ..........................\n",
            "[CV]  C=10, degree=4, gamma=0.01, kernel=rbf, score=0.760, total=  20.0s\n",
            "[CV] C=10, degree=4, gamma=0.01, kernel=rbf ..........................\n",
            "[CV]  C=10, degree=4, gamma=0.01, kernel=rbf, score=0.784, total=  20.1s\n",
            "[CV] C=10, degree=5, gamma=1, kernel=rbf .............................\n",
            "[CV] . C=10, degree=5, gamma=1, kernel=rbf, score=0.636, total= 1.4min\n",
            "[CV] C=10, degree=5, gamma=1, kernel=rbf .............................\n",
            "[CV] . C=10, degree=5, gamma=1, kernel=rbf, score=0.640, total= 1.4min\n",
            "[CV] C=10, degree=5, gamma=1, kernel=rbf .............................\n",
            "[CV] . C=10, degree=5, gamma=1, kernel=rbf, score=0.644, total= 1.5min\n",
            "[CV] C=10, degree=5, gamma=1, kernel=rbf .............................\n",
            "[CV] . C=10, degree=5, gamma=1, kernel=rbf, score=0.636, total= 1.4min\n",
            "[CV] C=10, degree=5, gamma=1, kernel=rbf .............................\n",
            "[CV] . C=10, degree=5, gamma=1, kernel=rbf, score=0.638, total= 1.4min\n",
            "[CV] C=10, degree=5, gamma=0.1, kernel=rbf ...........................\n",
            "[CV]  C=10, degree=5, gamma=0.1, kernel=rbf, score=0.749, total=  56.8s\n",
            "[CV] C=10, degree=5, gamma=0.1, kernel=rbf ...........................\n",
            "[CV]  C=10, degree=5, gamma=0.1, kernel=rbf, score=0.761, total=  57.9s\n",
            "[CV] C=10, degree=5, gamma=0.1, kernel=rbf ...........................\n",
            "[CV]  C=10, degree=5, gamma=0.1, kernel=rbf, score=0.751, total=  57.9s\n",
            "[CV] C=10, degree=5, gamma=0.1, kernel=rbf ...........................\n",
            "[CV]  C=10, degree=5, gamma=0.1, kernel=rbf, score=0.730, total=  55.9s\n",
            "[CV] C=10, degree=5, gamma=0.1, kernel=rbf ...........................\n",
            "[CV]  C=10, degree=5, gamma=0.1, kernel=rbf, score=0.747, total=  56.7s\n",
            "[CV] C=10, degree=5, gamma=0.01, kernel=rbf ..........................\n",
            "[CV]  C=10, degree=5, gamma=0.01, kernel=rbf, score=0.789, total=  20.9s\n",
            "[CV] C=10, degree=5, gamma=0.01, kernel=rbf ..........................\n",
            "[CV]  C=10, degree=5, gamma=0.01, kernel=rbf, score=0.788, total=  20.5s\n",
            "[CV] C=10, degree=5, gamma=0.01, kernel=rbf ..........................\n",
            "[CV]  C=10, degree=5, gamma=0.01, kernel=rbf, score=0.776, total=  20.4s\n",
            "[CV] C=10, degree=5, gamma=0.01, kernel=rbf ..........................\n",
            "[CV]  C=10, degree=5, gamma=0.01, kernel=rbf, score=0.760, total=  20.0s\n",
            "[CV] C=10, degree=5, gamma=0.01, kernel=rbf ..........................\n",
            "[CV]  C=10, degree=5, gamma=0.01, kernel=rbf, score=0.784, total=  20.3s\n",
            "[CV] C=100, degree=3, gamma=1, kernel=rbf ............................\n",
            "[CV]  C=100, degree=3, gamma=1, kernel=rbf, score=0.636, total= 1.4min\n",
            "[CV] C=100, degree=3, gamma=1, kernel=rbf ............................\n",
            "[CV]  C=100, degree=3, gamma=1, kernel=rbf, score=0.640, total= 1.4min\n",
            "[CV] C=100, degree=3, gamma=1, kernel=rbf ............................\n",
            "[CV]  C=100, degree=3, gamma=1, kernel=rbf, score=0.644, total= 1.5min\n",
            "[CV] C=100, degree=3, gamma=1, kernel=rbf ............................\n",
            "[CV]  C=100, degree=3, gamma=1, kernel=rbf, score=0.636, total= 1.4min\n",
            "[CV] C=100, degree=3, gamma=1, kernel=rbf ............................\n",
            "[CV]  C=100, degree=3, gamma=1, kernel=rbf, score=0.638, total= 1.4min\n",
            "[CV] C=100, degree=3, gamma=0.1, kernel=rbf ..........................\n",
            "[CV]  C=100, degree=3, gamma=0.1, kernel=rbf, score=0.737, total=  57.4s\n",
            "[CV] C=100, degree=3, gamma=0.1, kernel=rbf ..........................\n",
            "[CV]  C=100, degree=3, gamma=0.1, kernel=rbf, score=0.749, total=  57.8s\n",
            "[CV] C=100, degree=3, gamma=0.1, kernel=rbf ..........................\n",
            "[CV]  C=100, degree=3, gamma=0.1, kernel=rbf, score=0.744, total=  56.8s\n",
            "[CV] C=100, degree=3, gamma=0.1, kernel=rbf ..........................\n",
            "[CV]  C=100, degree=3, gamma=0.1, kernel=rbf, score=0.723, total=  55.3s\n",
            "[CV] C=100, degree=3, gamma=0.1, kernel=rbf ..........................\n",
            "[CV]  C=100, degree=3, gamma=0.1, kernel=rbf, score=0.740, total=  56.9s\n",
            "[CV] C=100, degree=3, gamma=0.01, kernel=rbf .........................\n",
            "[CV]  C=100, degree=3, gamma=0.01, kernel=rbf, score=0.799, total=  46.3s\n",
            "[CV] C=100, degree=3, gamma=0.01, kernel=rbf .........................\n",
            "[CV]  C=100, degree=3, gamma=0.01, kernel=rbf, score=0.793, total=  47.0s\n",
            "[CV] C=100, degree=3, gamma=0.01, kernel=rbf .........................\n",
            "[CV]  C=100, degree=3, gamma=0.01, kernel=rbf, score=0.778, total=  45.0s\n",
            "[CV] C=100, degree=3, gamma=0.01, kernel=rbf .........................\n",
            "[CV]  C=100, degree=3, gamma=0.01, kernel=rbf, score=0.769, total=  44.8s\n",
            "[CV] C=100, degree=3, gamma=0.01, kernel=rbf .........................\n",
            "[CV]  C=100, degree=3, gamma=0.01, kernel=rbf, score=0.780, total=  45.2s\n",
            "[CV] C=100, degree=4, gamma=1, kernel=rbf ............................\n",
            "[CV]  C=100, degree=4, gamma=1, kernel=rbf, score=0.636, total= 1.4min\n",
            "[CV] C=100, degree=4, gamma=1, kernel=rbf ............................\n",
            "[CV]  C=100, degree=4, gamma=1, kernel=rbf, score=0.640, total= 1.4min\n",
            "[CV] C=100, degree=4, gamma=1, kernel=rbf ............................\n",
            "[CV]  C=100, degree=4, gamma=1, kernel=rbf, score=0.644, total= 1.5min\n",
            "[CV] C=100, degree=4, gamma=1, kernel=rbf ............................\n",
            "[CV]  C=100, degree=4, gamma=1, kernel=rbf, score=0.636, total= 1.4min\n",
            "[CV] C=100, degree=4, gamma=1, kernel=rbf ............................\n",
            "[CV]  C=100, degree=4, gamma=1, kernel=rbf, score=0.638, total= 1.4min\n",
            "[CV] C=100, degree=4, gamma=0.1, kernel=rbf ..........................\n",
            "[CV]  C=100, degree=4, gamma=0.1, kernel=rbf, score=0.737, total=  57.5s\n",
            "[CV] C=100, degree=4, gamma=0.1, kernel=rbf ..........................\n",
            "[CV]  C=100, degree=4, gamma=0.1, kernel=rbf, score=0.749, total=  58.3s\n",
            "[CV] C=100, degree=4, gamma=0.1, kernel=rbf ..........................\n",
            "[CV]  C=100, degree=4, gamma=0.1, kernel=rbf, score=0.744, total=  58.0s\n",
            "[CV] C=100, degree=4, gamma=0.1, kernel=rbf ..........................\n",
            "[CV]  C=100, degree=4, gamma=0.1, kernel=rbf, score=0.723, total=  56.1s\n",
            "[CV] C=100, degree=4, gamma=0.1, kernel=rbf ..........................\n",
            "[CV]  C=100, degree=4, gamma=0.1, kernel=rbf, score=0.740, total=  57.2s\n",
            "[CV] C=100, degree=4, gamma=0.01, kernel=rbf .........................\n",
            "[CV]  C=100, degree=4, gamma=0.01, kernel=rbf, score=0.799, total=  46.4s\n",
            "[CV] C=100, degree=4, gamma=0.01, kernel=rbf .........................\n",
            "[CV]  C=100, degree=4, gamma=0.01, kernel=rbf, score=0.793, total=  46.9s\n",
            "[CV] C=100, degree=4, gamma=0.01, kernel=rbf .........................\n",
            "[CV]  C=100, degree=4, gamma=0.01, kernel=rbf, score=0.778, total=  44.9s\n",
            "[CV] C=100, degree=4, gamma=0.01, kernel=rbf .........................\n",
            "[CV]  C=100, degree=4, gamma=0.01, kernel=rbf, score=0.769, total=  44.5s\n",
            "[CV] C=100, degree=4, gamma=0.01, kernel=rbf .........................\n",
            "[CV]  C=100, degree=4, gamma=0.01, kernel=rbf, score=0.780, total=  45.3s\n",
            "[CV] C=100, degree=5, gamma=1, kernel=rbf ............................\n",
            "[CV]  C=100, degree=5, gamma=1, kernel=rbf, score=0.636, total= 1.4min\n",
            "[CV] C=100, degree=5, gamma=1, kernel=rbf ............................\n",
            "[CV]  C=100, degree=5, gamma=1, kernel=rbf, score=0.640, total= 1.4min\n",
            "[CV] C=100, degree=5, gamma=1, kernel=rbf ............................\n",
            "[CV]  C=100, degree=5, gamma=1, kernel=rbf, score=0.644, total= 1.5min\n",
            "[CV] C=100, degree=5, gamma=1, kernel=rbf ............................\n",
            "[CV]  C=100, degree=5, gamma=1, kernel=rbf, score=0.636, total= 1.4min\n",
            "[CV] C=100, degree=5, gamma=1, kernel=rbf ............................\n",
            "[CV]  C=100, degree=5, gamma=1, kernel=rbf, score=0.638, total= 1.4min\n",
            "[CV] C=100, degree=5, gamma=0.1, kernel=rbf ..........................\n",
            "[CV]  C=100, degree=5, gamma=0.1, kernel=rbf, score=0.737, total=  56.8s\n",
            "[CV] C=100, degree=5, gamma=0.1, kernel=rbf ..........................\n",
            "[CV]  C=100, degree=5, gamma=0.1, kernel=rbf, score=0.749, total=  57.4s\n",
            "[CV] C=100, degree=5, gamma=0.1, kernel=rbf ..........................\n",
            "[CV]  C=100, degree=5, gamma=0.1, kernel=rbf, score=0.744, total=  56.8s\n",
            "[CV] C=100, degree=5, gamma=0.1, kernel=rbf ..........................\n",
            "[CV]  C=100, degree=5, gamma=0.1, kernel=rbf, score=0.723, total=  55.4s\n",
            "[CV] C=100, degree=5, gamma=0.1, kernel=rbf ..........................\n",
            "[CV]  C=100, degree=5, gamma=0.1, kernel=rbf, score=0.740, total=  57.1s\n",
            "[CV] C=100, degree=5, gamma=0.01, kernel=rbf .........................\n",
            "[CV]  C=100, degree=5, gamma=0.01, kernel=rbf, score=0.799, total=  46.4s\n",
            "[CV] C=100, degree=5, gamma=0.01, kernel=rbf .........................\n",
            "[CV]  C=100, degree=5, gamma=0.01, kernel=rbf, score=0.793, total=  46.6s\n",
            "[CV] C=100, degree=5, gamma=0.01, kernel=rbf .........................\n",
            "[CV]  C=100, degree=5, gamma=0.01, kernel=rbf, score=0.778, total=  45.0s\n",
            "[CV] C=100, degree=5, gamma=0.01, kernel=rbf .........................\n",
            "[CV]  C=100, degree=5, gamma=0.01, kernel=rbf, score=0.769, total=  43.9s\n",
            "[CV] C=100, degree=5, gamma=0.01, kernel=rbf .........................\n",
            "[CV]  C=100, degree=5, gamma=0.01, kernel=rbf, score=0.780, total=  45.3s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 135 out of 135 | elapsed: 116.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=None, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [1, 10, 100], 'degree': [3, 4, 5],\n",
              "                         'gamma': [1, 0.1, 0.01], 'kernel': ['rbf']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiVKsOK7ZbDY",
        "outputId": "ab9a00e3-06c9-4f8e-e53e-681e301f458d"
      },
      "source": [
        "print(grid.best_params_)\n",
        "print(grid.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'C': 100, 'degree': 3, 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0B7meN5Dxho"
      },
      "source": [
        "svc = SVC(C = 100, kernel = 'rbf', gamma = 0.01, degree = 3)\n",
        "svc.fit(X_train, y_train)\n",
        "y_pred = svc.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQnyhOsVEO7S",
        "outputId": "296955bf-2e52-46bb-d828-818b8e4dfc6a"
      },
      "source": [
        "print(svc.score(X_train, y_train))\n",
        "print(svc.score(X_test, y_test))\n",
        "print(precision_score(y_pred, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8832331730769231\n",
            "0.7908653846153846\n",
            "0.8333333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9z9d2J8EkBr",
        "outputId": "5961885b-c0d8-4e4d-9e56-69a6aca19589"
      },
      "source": [
        "logreg_grid = {'C' : [0.01, 0.1, 1, 10],\n",
        "               'solver' : ['saga', 'liblinear'],\n",
        "               'penalty' : ['l1', 'l2', 'elasticnet'],\n",
        "               'l1_ratio' : [0.2, 0.4, 0.5]}\n",
        "\n",
        "grid_logreg = GridSearchCV(LogisticRegression(max_iter = 50000), logreg_grid, verbose = 4, refit = True)\n",
        "grid_logreg.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=l1, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.2, penalty=l1, solver=saga, score=0.671, total=   2.5s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=l1, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s remaining:    0.0s\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.2, penalty=l1, solver=saga, score=0.670, total=   2.5s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=l1, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.0s remaining:    0.0s\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.2, penalty=l1, solver=saga, score=0.653, total=   2.2s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=l1, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    7.2s remaining:    0.0s\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.2, penalty=l1, solver=saga, score=0.648, total=   2.6s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=l1, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.2, penalty=l1, solver=saga, score=0.658, total=   2.7s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=l1, solver=liblinear ..............\n",
            "[CV]  C=0.01, l1_ratio=0.2, penalty=l1, solver=liblinear, score=0.665, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=l1, solver=liblinear ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.2, penalty=l1, solver=liblinear, score=0.661, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=l1, solver=liblinear ..............\n",
            "[CV]  C=0.01, l1_ratio=0.2, penalty=l1, solver=liblinear, score=0.651, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=l1, solver=liblinear ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.2, penalty=l1, solver=liblinear, score=0.639, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=l1, solver=liblinear ..............\n",
            "[CV]  C=0.01, l1_ratio=0.2, penalty=l1, solver=liblinear, score=0.665, total=   0.2s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=l2, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.2, penalty=l2, solver=saga, score=0.672, total=   2.1s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=l2, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.2, penalty=l2, solver=saga, score=0.667, total=   2.1s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=l2, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.2, penalty=l2, solver=saga, score=0.654, total=   1.8s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=l2, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.2, penalty=l2, solver=saga, score=0.646, total=   2.1s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=l2, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.2, penalty=l2, solver=saga, score=0.658, total=   2.2s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=l2, solver=liblinear ..............\n",
            "[CV]  C=0.01, l1_ratio=0.2, penalty=l2, solver=liblinear, score=0.675, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=l2, solver=liblinear ..............\n",
            "[CV]  C=0.01, l1_ratio=0.2, penalty=l2, solver=liblinear, score=0.666, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=l2, solver=liblinear ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.2, penalty=l2, solver=liblinear, score=0.657, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=l2, solver=liblinear ..............\n",
            "[CV]  C=0.01, l1_ratio=0.2, penalty=l2, solver=liblinear, score=0.644, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=l2, solver=liblinear ..............\n",
            "[CV]  C=0.01, l1_ratio=0.2, penalty=l2, solver=liblinear, score=0.663, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=saga ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=saga, score=0.672, total=   2.7s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=saga ...........\n",
            "[CV]  C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=saga, score=0.667, total=   2.7s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=saga ...........\n",
            "[CV]  C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=saga, score=0.654, total=   2.2s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=saga ...........\n",
            "[CV]  C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=saga, score=0.647, total=   2.6s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=saga ...........\n",
            "[CV]  C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=saga, score=0.658, total=   2.8s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=liblinear ......\n",
            "[CV]  C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=liblinear ......\n",
            "[CV]  C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=liblinear ......\n",
            "[CV]  C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=liblinear ......\n",
            "[CV]  C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=liblinear ......\n",
            "[CV]  C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=l1, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.4, penalty=l1, solver=saga, score=0.671, total=   2.5s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=l1, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.4, penalty=l1, solver=saga, score=0.670, total=   2.5s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=l1, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.4, penalty=l1, solver=saga, score=0.653, total=   2.2s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=l1, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.4, penalty=l1, solver=saga, score=0.648, total=   2.5s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=l1, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.4, penalty=l1, solver=saga, score=0.658, total=   2.6s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=l1, solver=liblinear ..............\n",
            "[CV]  C=0.01, l1_ratio=0.4, penalty=l1, solver=liblinear, score=0.665, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=l1, solver=liblinear ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.4, penalty=l1, solver=liblinear, score=0.661, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=l1, solver=liblinear ..............\n",
            "[CV]  C=0.01, l1_ratio=0.4, penalty=l1, solver=liblinear, score=0.651, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=l1, solver=liblinear ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.4, penalty=l1, solver=liblinear, score=0.639, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=l1, solver=liblinear ..............\n",
            "[CV]  C=0.01, l1_ratio=0.4, penalty=l1, solver=liblinear, score=0.665, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=l2, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.4, penalty=l2, solver=saga, score=0.672, total=   2.1s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=l2, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.4, penalty=l2, solver=saga, score=0.667, total=   2.1s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=l2, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.4, penalty=l2, solver=saga, score=0.654, total=   1.8s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=l2, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.4, penalty=l2, solver=saga, score=0.646, total=   2.1s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=l2, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.4, penalty=l2, solver=saga, score=0.658, total=   2.1s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=l2, solver=liblinear ..............\n",
            "[CV]  C=0.01, l1_ratio=0.4, penalty=l2, solver=liblinear, score=0.675, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=l2, solver=liblinear ..............\n",
            "[CV]  C=0.01, l1_ratio=0.4, penalty=l2, solver=liblinear, score=0.666, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=l2, solver=liblinear ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.4, penalty=l2, solver=liblinear, score=0.657, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=l2, solver=liblinear ..............\n",
            "[CV]  C=0.01, l1_ratio=0.4, penalty=l2, solver=liblinear, score=0.644, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=l2, solver=liblinear ..............\n",
            "[CV]  C=0.01, l1_ratio=0.4, penalty=l2, solver=liblinear, score=0.663, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=saga ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=saga, score=0.672, total=   2.7s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=saga ...........\n",
            "[CV]  C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=saga, score=0.668, total=   2.7s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=saga ...........\n",
            "[CV]  C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=saga, score=0.654, total=   2.3s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=saga ...........\n",
            "[CV]  C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=saga, score=0.648, total=   2.7s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=saga ...........\n",
            "[CV]  C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=saga, score=0.659, total=   2.8s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=liblinear ......\n",
            "[CV]  C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=liblinear ......\n",
            "[CV]  C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=liblinear ......\n",
            "[CV]  C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=liblinear ......\n",
            "[CV]  C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=liblinear ......\n",
            "[CV]  C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=l1, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.5, penalty=l1, solver=saga, score=0.671, total=   2.5s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=l1, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.5, penalty=l1, solver=saga, score=0.670, total=   2.5s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=l1, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.5, penalty=l1, solver=saga, score=0.653, total=   2.2s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=l1, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.5, penalty=l1, solver=saga, score=0.648, total=   2.7s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=l1, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.5, penalty=l1, solver=saga, score=0.658, total=   2.7s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=l1, solver=liblinear ..............\n",
            "[CV]  C=0.01, l1_ratio=0.5, penalty=l1, solver=liblinear, score=0.665, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=l1, solver=liblinear ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.5, penalty=l1, solver=liblinear, score=0.661, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=l1, solver=liblinear ..............\n",
            "[CV]  C=0.01, l1_ratio=0.5, penalty=l1, solver=liblinear, score=0.651, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=l1, solver=liblinear ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.5, penalty=l1, solver=liblinear, score=0.639, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=l1, solver=liblinear ..............\n",
            "[CV]  C=0.01, l1_ratio=0.5, penalty=l1, solver=liblinear, score=0.665, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=l2, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.5, penalty=l2, solver=saga, score=0.672, total=   2.1s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=l2, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.5, penalty=l2, solver=saga, score=0.667, total=   2.2s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=l2, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.5, penalty=l2, solver=saga, score=0.654, total=   1.9s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=l2, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.5, penalty=l2, solver=saga, score=0.646, total=   2.2s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=l2, solver=saga ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.5, penalty=l2, solver=saga, score=0.658, total=   2.2s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=l2, solver=liblinear ..............\n",
            "[CV]  C=0.01, l1_ratio=0.5, penalty=l2, solver=liblinear, score=0.675, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=l2, solver=liblinear ..............\n",
            "[CV]  C=0.01, l1_ratio=0.5, penalty=l2, solver=liblinear, score=0.666, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=l2, solver=liblinear ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.5, penalty=l2, solver=liblinear, score=0.657, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=l2, solver=liblinear ..............\n",
            "[CV]  C=0.01, l1_ratio=0.5, penalty=l2, solver=liblinear, score=0.644, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=l2, solver=liblinear ..............\n",
            "[CV]  C=0.01, l1_ratio=0.5, penalty=l2, solver=liblinear, score=0.663, total=   0.1s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga, score=0.672, total=   2.7s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga ...........\n",
            "[CV]  C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga, score=0.669, total=   2.7s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga ...........\n",
            "[CV]  C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga, score=0.653, total=   2.3s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga ...........\n",
            "[CV]  C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga, score=0.648, total=   2.8s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga ...........\n",
            "[CV]  C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga, score=0.657, total=   2.8s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=liblinear ......\n",
            "[CV]  C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=liblinear ......\n",
            "[CV]  C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=liblinear ......\n",
            "[CV]  C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=liblinear ......\n",
            "[CV]  C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=liblinear ......\n",
            "[CV]  C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=l1, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.2, penalty=l1, solver=saga, score=0.673, total=   3.9s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=l1, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.2, penalty=l1, solver=saga, score=0.666, total=   3.8s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=l1, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.2, penalty=l1, solver=saga, score=0.654, total=   2.0s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=l1, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.2, penalty=l1, solver=saga, score=0.646, total=   6.5s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=l1, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.2, penalty=l1, solver=saga, score=0.659, total=   4.6s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=l1, solver=liblinear ...............\n",
            "[CV]  C=0.1, l1_ratio=0.2, penalty=l1, solver=liblinear, score=0.671, total=   0.2s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=l1, solver=liblinear ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.2, penalty=l1, solver=liblinear, score=0.669, total=   0.2s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=l1, solver=liblinear ...............\n",
            "[CV]  C=0.1, l1_ratio=0.2, penalty=l1, solver=liblinear, score=0.654, total=   0.1s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=l1, solver=liblinear ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.2, penalty=l1, solver=liblinear, score=0.646, total=   0.1s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=l1, solver=liblinear ...............\n",
            "[CV]  C=0.1, l1_ratio=0.2, penalty=l1, solver=liblinear, score=0.659, total=   0.2s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=l2, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.2, penalty=l2, solver=saga, score=0.673, total=   6.4s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=l2, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.2, penalty=l2, solver=saga, score=0.666, total=   4.7s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=l2, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.2, penalty=l2, solver=saga, score=0.654, total=   5.8s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=l2, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.2, penalty=l2, solver=saga, score=0.646, total=   4.9s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=l2, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.2, penalty=l2, solver=saga, score=0.658, total=   5.6s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=l2, solver=liblinear ...............\n",
            "[CV]  C=0.1, l1_ratio=0.2, penalty=l2, solver=liblinear, score=0.672, total=   0.1s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=l2, solver=liblinear ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.2, penalty=l2, solver=liblinear, score=0.668, total=   0.1s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=l2, solver=liblinear ...............\n",
            "[CV]  C=0.1, l1_ratio=0.2, penalty=l2, solver=liblinear, score=0.654, total=   0.1s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=l2, solver=liblinear ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.2, penalty=l2, solver=liblinear, score=0.646, total=   0.1s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=l2, solver=liblinear ...............\n",
            "[CV]  C=0.1, l1_ratio=0.2, penalty=l2, solver=liblinear, score=0.660, total=   0.1s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=saga ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=saga, score=0.672, total=   7.7s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=saga ............\n",
            "[CV]  C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=saga, score=0.666, total=   6.3s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=saga ............\n",
            "[CV]  C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=saga, score=0.654, total=   8.1s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=saga ............\n",
            "[CV]  C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=saga, score=0.646, total=   6.7s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=saga ............\n",
            "[CV]  C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=saga, score=0.658, total=   7.2s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=liblinear .......\n",
            "[CV]  C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=liblinear .......\n",
            "[CV]  C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=liblinear .......\n",
            "[CV]  C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=liblinear .......\n",
            "[CV]  C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=liblinear .......\n",
            "[CV]  C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=l1, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.4, penalty=l1, solver=saga, score=0.673, total=   3.9s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=l1, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.4, penalty=l1, solver=saga, score=0.666, total=   3.9s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=l1, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.4, penalty=l1, solver=saga, score=0.654, total=   2.0s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=l1, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.4, penalty=l1, solver=saga, score=0.646, total=   6.3s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=l1, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.4, penalty=l1, solver=saga, score=0.659, total=   4.8s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=l1, solver=liblinear ...............\n",
            "[CV]  C=0.1, l1_ratio=0.4, penalty=l1, solver=liblinear, score=0.671, total=   0.2s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=l1, solver=liblinear ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.4, penalty=l1, solver=liblinear, score=0.669, total=   0.2s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=l1, solver=liblinear ...............\n",
            "[CV]  C=0.1, l1_ratio=0.4, penalty=l1, solver=liblinear, score=0.654, total=   0.1s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=l1, solver=liblinear ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.4, penalty=l1, solver=liblinear, score=0.646, total=   0.2s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=l1, solver=liblinear ...............\n",
            "[CV]  C=0.1, l1_ratio=0.4, penalty=l1, solver=liblinear, score=0.659, total=   0.2s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=l2, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.4, penalty=l2, solver=saga, score=0.673, total=   6.4s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=l2, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.4, penalty=l2, solver=saga, score=0.666, total=   4.6s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=l2, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.4, penalty=l2, solver=saga, score=0.654, total=   5.7s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=l2, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.4, penalty=l2, solver=saga, score=0.646, total=   5.1s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=l2, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.4, penalty=l2, solver=saga, score=0.658, total=   5.8s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=l2, solver=liblinear ...............\n",
            "[CV]  C=0.1, l1_ratio=0.4, penalty=l2, solver=liblinear, score=0.672, total=   0.1s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=l2, solver=liblinear ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.4, penalty=l2, solver=liblinear, score=0.668, total=   0.1s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=l2, solver=liblinear ...............\n",
            "[CV]  C=0.1, l1_ratio=0.4, penalty=l2, solver=liblinear, score=0.654, total=   0.1s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=l2, solver=liblinear ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.4, penalty=l2, solver=liblinear, score=0.646, total=   0.1s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=l2, solver=liblinear ...............\n",
            "[CV]  C=0.1, l1_ratio=0.4, penalty=l2, solver=liblinear, score=0.660, total=   0.1s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=saga ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=saga, score=0.672, total=   5.9s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=saga ............\n",
            "[CV]  C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=saga, score=0.667, total=   6.7s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=saga ............\n",
            "[CV]  C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=saga, score=0.654, total=   8.4s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=saga ............\n",
            "[CV]  C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=saga, score=0.647, total=   7.2s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=saga ............\n",
            "[CV]  C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=saga, score=0.658, total=   6.6s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=liblinear .......\n",
            "[CV]  C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=liblinear .......\n",
            "[CV]  C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=liblinear .......\n",
            "[CV]  C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=liblinear .......\n",
            "[CV]  C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=liblinear .......\n",
            "[CV]  C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=l1, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.5, penalty=l1, solver=saga, score=0.673, total=   3.8s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=l1, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.5, penalty=l1, solver=saga, score=0.666, total=   3.7s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=l1, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.5, penalty=l1, solver=saga, score=0.654, total=   1.9s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=l1, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.5, penalty=l1, solver=saga, score=0.646, total=   6.4s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=l1, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.5, penalty=l1, solver=saga, score=0.659, total=   4.8s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=l1, solver=liblinear ...............\n",
            "[CV]  C=0.1, l1_ratio=0.5, penalty=l1, solver=liblinear, score=0.671, total=   0.1s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=l1, solver=liblinear ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.5, penalty=l1, solver=liblinear, score=0.669, total=   0.2s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=l1, solver=liblinear ...............\n",
            "[CV]  C=0.1, l1_ratio=0.5, penalty=l1, solver=liblinear, score=0.654, total=   0.2s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=l1, solver=liblinear ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.5, penalty=l1, solver=liblinear, score=0.646, total=   0.2s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=l1, solver=liblinear ...............\n",
            "[CV]  C=0.1, l1_ratio=0.5, penalty=l1, solver=liblinear, score=0.659, total=   0.2s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=l2, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.5, penalty=l2, solver=saga, score=0.673, total=   6.4s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=l2, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.5, penalty=l2, solver=saga, score=0.666, total=   4.8s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=l2, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.5, penalty=l2, solver=saga, score=0.654, total=   5.6s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=l2, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.5, penalty=l2, solver=saga, score=0.646, total=   4.8s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=l2, solver=saga ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.5, penalty=l2, solver=saga, score=0.658, total=   5.5s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=l2, solver=liblinear ...............\n",
            "[CV]  C=0.1, l1_ratio=0.5, penalty=l2, solver=liblinear, score=0.672, total=   0.1s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=l2, solver=liblinear ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.5, penalty=l2, solver=liblinear, score=0.668, total=   0.1s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=l2, solver=liblinear ...............\n",
            "[CV]  C=0.1, l1_ratio=0.5, penalty=l2, solver=liblinear, score=0.654, total=   0.1s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=l2, solver=liblinear ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.5, penalty=l2, solver=liblinear, score=0.646, total=   0.1s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=l2, solver=liblinear ...............\n",
            "[CV]  C=0.1, l1_ratio=0.5, penalty=l2, solver=liblinear, score=0.660, total=   0.1s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga, score=0.673, total=   5.2s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga ............\n",
            "[CV]  C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga, score=0.666, total=   6.9s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga ............\n",
            "[CV]  C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga, score=0.654, total=   7.5s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga ............\n",
            "[CV]  C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga, score=0.647, total=   7.2s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga ............\n",
            "[CV]  C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga, score=0.658, total=   6.5s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=liblinear .......\n",
            "[CV]  C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=liblinear .......\n",
            "[CV]  C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=liblinear .......\n",
            "[CV]  C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=liblinear .......\n",
            "[CV]  C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=liblinear .......\n",
            "[CV]  C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=l1, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.2, penalty=l1, solver=saga, score=0.672, total=  16.7s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=l1, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.2, penalty=l1, solver=saga, score=0.666, total=  13.9s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=l1, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.2, penalty=l1, solver=saga, score=0.654, total=  34.2s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=l1, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.2, penalty=l1, solver=saga, score=0.646, total=  15.4s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=l1, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.2, penalty=l1, solver=saga, score=0.658, total=  15.0s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=l1, solver=liblinear .................\n",
            "[CV]  C=1, l1_ratio=0.2, penalty=l1, solver=liblinear, score=0.673, total=   0.2s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=l1, solver=liblinear .................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.2, penalty=l1, solver=liblinear, score=0.667, total=   0.2s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=l1, solver=liblinear .................\n",
            "[CV]  C=1, l1_ratio=0.2, penalty=l1, solver=liblinear, score=0.654, total=   0.2s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=l1, solver=liblinear .................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.2, penalty=l1, solver=liblinear, score=0.647, total=   0.2s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=l1, solver=liblinear .................\n",
            "[CV]  C=1, l1_ratio=0.2, penalty=l1, solver=liblinear, score=0.658, total=   0.2s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=l2, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.2, penalty=l2, solver=saga, score=0.672, total=  21.8s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=l2, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.2, penalty=l2, solver=saga, score=0.666, total=  12.8s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=l2, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.2, penalty=l2, solver=saga, score=0.654, total=  20.2s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=l2, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.2, penalty=l2, solver=saga, score=0.647, total=  13.7s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=l2, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.2, penalty=l2, solver=saga, score=0.658, total=  14.3s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=l2, solver=liblinear .................\n",
            "[CV]  C=1, l1_ratio=0.2, penalty=l2, solver=liblinear, score=0.672, total=   0.2s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=l2, solver=liblinear .................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.2, penalty=l2, solver=liblinear, score=0.666, total=   0.2s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=l2, solver=liblinear .................\n",
            "[CV]  C=1, l1_ratio=0.2, penalty=l2, solver=liblinear, score=0.654, total=   0.1s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=l2, solver=liblinear .................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.2, penalty=l2, solver=liblinear, score=0.647, total=   0.2s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=l2, solver=liblinear .................\n",
            "[CV]  C=1, l1_ratio=0.2, penalty=l2, solver=liblinear, score=0.659, total=   0.1s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=elasticnet, solver=saga ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.2, penalty=elasticnet, solver=saga, score=0.673, total=  28.0s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=elasticnet, solver=saga ..............\n",
            "[CV]  C=1, l1_ratio=0.2, penalty=elasticnet, solver=saga, score=0.666, total=  17.3s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=elasticnet, solver=saga ..............\n",
            "[CV]  C=1, l1_ratio=0.2, penalty=elasticnet, solver=saga, score=0.654, total=  27.3s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=elasticnet, solver=saga ..............\n",
            "[CV]  C=1, l1_ratio=0.2, penalty=elasticnet, solver=saga, score=0.647, total=  18.2s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=elasticnet, solver=saga ..............\n",
            "[CV]  C=1, l1_ratio=0.2, penalty=elasticnet, solver=saga, score=0.658, total=  18.3s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=elasticnet, solver=liblinear .........\n",
            "[CV]  C=1, l1_ratio=0.2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=elasticnet, solver=liblinear .........\n",
            "[CV]  C=1, l1_ratio=0.2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=elasticnet, solver=liblinear .........\n",
            "[CV]  C=1, l1_ratio=0.2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=elasticnet, solver=liblinear .........\n",
            "[CV]  C=1, l1_ratio=0.2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=1, l1_ratio=0.2, penalty=elasticnet, solver=liblinear .........\n",
            "[CV]  C=1, l1_ratio=0.2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=l1, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.4, penalty=l1, solver=saga, score=0.672, total=  16.9s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=l1, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.4, penalty=l1, solver=saga, score=0.666, total=  14.1s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=l1, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.4, penalty=l1, solver=saga, score=0.654, total=  33.8s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=l1, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.4, penalty=l1, solver=saga, score=0.646, total=  15.6s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=l1, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.4, penalty=l1, solver=saga, score=0.658, total=  15.0s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=l1, solver=liblinear .................\n",
            "[CV]  C=1, l1_ratio=0.4, penalty=l1, solver=liblinear, score=0.673, total=   0.2s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=l1, solver=liblinear .................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.4, penalty=l1, solver=liblinear, score=0.667, total=   0.2s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=l1, solver=liblinear .................\n",
            "[CV]  C=1, l1_ratio=0.4, penalty=l1, solver=liblinear, score=0.654, total=   0.1s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=l1, solver=liblinear .................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.4, penalty=l1, solver=liblinear, score=0.647, total=   0.2s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=l1, solver=liblinear .................\n",
            "[CV]  C=1, l1_ratio=0.4, penalty=l1, solver=liblinear, score=0.658, total=   0.2s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=l2, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.4, penalty=l2, solver=saga, score=0.672, total=  21.8s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=l2, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.4, penalty=l2, solver=saga, score=0.666, total=  12.8s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=l2, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.4, penalty=l2, solver=saga, score=0.654, total=  20.1s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=l2, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.4, penalty=l2, solver=saga, score=0.647, total=  13.7s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=l2, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.4, penalty=l2, solver=saga, score=0.658, total=  13.9s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=l2, solver=liblinear .................\n",
            "[CV]  C=1, l1_ratio=0.4, penalty=l2, solver=liblinear, score=0.672, total=   0.2s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=l2, solver=liblinear .................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.4, penalty=l2, solver=liblinear, score=0.666, total=   0.2s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=l2, solver=liblinear .................\n",
            "[CV]  C=1, l1_ratio=0.4, penalty=l2, solver=liblinear, score=0.654, total=   0.1s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=l2, solver=liblinear .................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.4, penalty=l2, solver=liblinear, score=0.647, total=   0.2s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=l2, solver=liblinear .................\n",
            "[CV]  C=1, l1_ratio=0.4, penalty=l2, solver=liblinear, score=0.659, total=   0.1s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=elasticnet, solver=saga ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.4, penalty=elasticnet, solver=saga, score=0.673, total=  27.4s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=elasticnet, solver=saga ..............\n",
            "[CV]  C=1, l1_ratio=0.4, penalty=elasticnet, solver=saga, score=0.666, total=  17.2s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=elasticnet, solver=saga ..............\n",
            "[CV]  C=1, l1_ratio=0.4, penalty=elasticnet, solver=saga, score=0.654, total=  30.0s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=elasticnet, solver=saga ..............\n",
            "[CV]  C=1, l1_ratio=0.4, penalty=elasticnet, solver=saga, score=0.647, total=  18.2s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=elasticnet, solver=saga ..............\n",
            "[CV]  C=1, l1_ratio=0.4, penalty=elasticnet, solver=saga, score=0.658, total=  18.2s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=elasticnet, solver=liblinear .........\n",
            "[CV]  C=1, l1_ratio=0.4, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=elasticnet, solver=liblinear .........\n",
            "[CV]  C=1, l1_ratio=0.4, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=elasticnet, solver=liblinear .........\n",
            "[CV]  C=1, l1_ratio=0.4, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=elasticnet, solver=liblinear .........\n",
            "[CV]  C=1, l1_ratio=0.4, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=1, l1_ratio=0.4, penalty=elasticnet, solver=liblinear .........\n",
            "[CV]  C=1, l1_ratio=0.4, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=l1, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.5, penalty=l1, solver=saga, score=0.672, total=  16.6s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=l1, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.5, penalty=l1, solver=saga, score=0.666, total=  14.1s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=l1, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.5, penalty=l1, solver=saga, score=0.654, total=  34.3s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=l1, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.5, penalty=l1, solver=saga, score=0.646, total=  15.9s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=l1, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.5, penalty=l1, solver=saga, score=0.658, total=  15.2s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=l1, solver=liblinear .................\n",
            "[CV]  C=1, l1_ratio=0.5, penalty=l1, solver=liblinear, score=0.673, total=   0.2s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=l1, solver=liblinear .................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.5, penalty=l1, solver=liblinear, score=0.667, total=   0.2s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=l1, solver=liblinear .................\n",
            "[CV]  C=1, l1_ratio=0.5, penalty=l1, solver=liblinear, score=0.654, total=   0.1s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=l1, solver=liblinear .................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.5, penalty=l1, solver=liblinear, score=0.647, total=   0.2s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=l1, solver=liblinear .................\n",
            "[CV]  C=1, l1_ratio=0.5, penalty=l1, solver=liblinear, score=0.658, total=   0.1s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=l2, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.5, penalty=l2, solver=saga, score=0.672, total=  22.1s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=l2, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.5, penalty=l2, solver=saga, score=0.666, total=  12.9s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=l2, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.5, penalty=l2, solver=saga, score=0.654, total=  20.3s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=l2, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.5, penalty=l2, solver=saga, score=0.647, total=  13.8s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=l2, solver=saga ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.5, penalty=l2, solver=saga, score=0.658, total=  14.4s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=l2, solver=liblinear .................\n",
            "[CV]  C=1, l1_ratio=0.5, penalty=l2, solver=liblinear, score=0.672, total=   0.2s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=l2, solver=liblinear .................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.5, penalty=l2, solver=liblinear, score=0.666, total=   0.2s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=l2, solver=liblinear .................\n",
            "[CV]  C=1, l1_ratio=0.5, penalty=l2, solver=liblinear, score=0.654, total=   0.1s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=l2, solver=liblinear .................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.5, penalty=l2, solver=liblinear, score=0.647, total=   0.2s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=l2, solver=liblinear .................\n",
            "[CV]  C=1, l1_ratio=0.5, penalty=l2, solver=liblinear, score=0.659, total=   0.1s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga, score=0.673, total=  27.2s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga ..............\n",
            "[CV]  C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga, score=0.666, total=  16.3s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga ..............\n",
            "[CV]  C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga, score=0.654, total=  29.0s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga ..............\n",
            "[CV]  C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga, score=0.647, total=  18.3s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga ..............\n",
            "[CV]  C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga, score=0.658, total=  17.8s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=elasticnet, solver=liblinear .........\n",
            "[CV]  C=1, l1_ratio=0.5, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=elasticnet, solver=liblinear .........\n",
            "[CV]  C=1, l1_ratio=0.5, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=elasticnet, solver=liblinear .........\n",
            "[CV]  C=1, l1_ratio=0.5, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=elasticnet, solver=liblinear .........\n",
            "[CV]  C=1, l1_ratio=0.5, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=1, l1_ratio=0.5, penalty=elasticnet, solver=liblinear .........\n",
            "[CV]  C=1, l1_ratio=0.5, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=l1, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.2, penalty=l1, solver=saga, score=0.672, total=  46.3s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=l1, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.2, penalty=l1, solver=saga, score=0.666, total=  27.3s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=l1, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.2, penalty=l1, solver=saga, score=0.654, total=  40.3s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=l1, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.2, penalty=l1, solver=saga, score=0.647, total=  28.5s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=l1, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.2, penalty=l1, solver=saga, score=0.658, total=  27.3s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=l1, solver=liblinear ................\n",
            "[CV]  C=10, l1_ratio=0.2, penalty=l1, solver=liblinear, score=0.672, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=l1, solver=liblinear ................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.2, penalty=l1, solver=liblinear, score=0.666, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=l1, solver=liblinear ................\n",
            "[CV]  C=10, l1_ratio=0.2, penalty=l1, solver=liblinear, score=0.654, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=l1, solver=liblinear ................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.2, penalty=l1, solver=liblinear, score=0.647, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=l1, solver=liblinear ................\n",
            "[CV]  C=10, l1_ratio=0.2, penalty=l1, solver=liblinear, score=0.659, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=l2, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.2, penalty=l2, solver=saga, score=0.672, total=  35.6s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=l2, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.2, penalty=l2, solver=saga, score=0.666, total=  21.7s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=l2, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.2, penalty=l2, solver=saga, score=0.654, total=  32.3s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=l2, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.2, penalty=l2, solver=saga, score=0.647, total=  22.6s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=l2, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.2, penalty=l2, solver=saga, score=0.658, total=  22.1s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=l2, solver=liblinear ................\n",
            "[CV]  C=10, l1_ratio=0.2, penalty=l2, solver=liblinear, score=0.672, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=l2, solver=liblinear ................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.2, penalty=l2, solver=liblinear, score=0.666, total=   0.1s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=l2, solver=liblinear ................\n",
            "[CV]  C=10, l1_ratio=0.2, penalty=l2, solver=liblinear, score=0.654, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=l2, solver=liblinear ................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.2, penalty=l2, solver=liblinear, score=0.647, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=l2, solver=liblinear ................\n",
            "[CV]  C=10, l1_ratio=0.2, penalty=l2, solver=liblinear, score=0.659, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=elasticnet, solver=saga .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.2, penalty=elasticnet, solver=saga, score=0.672, total=  47.0s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=elasticnet, solver=saga .............\n",
            "[CV]  C=10, l1_ratio=0.2, penalty=elasticnet, solver=saga, score=0.666, total=  28.5s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=elasticnet, solver=saga .............\n",
            "[CV]  C=10, l1_ratio=0.2, penalty=elasticnet, solver=saga, score=0.654, total=  41.4s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=elasticnet, solver=saga .............\n",
            "[CV]  C=10, l1_ratio=0.2, penalty=elasticnet, solver=saga, score=0.647, total=  29.3s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=elasticnet, solver=saga .............\n",
            "[CV]  C=10, l1_ratio=0.2, penalty=elasticnet, solver=saga, score=0.658, total=  28.4s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=elasticnet, solver=liblinear ........\n",
            "[CV]  C=10, l1_ratio=0.2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=elasticnet, solver=liblinear ........\n",
            "[CV]  C=10, l1_ratio=0.2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=elasticnet, solver=liblinear ........\n",
            "[CV]  C=10, l1_ratio=0.2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=elasticnet, solver=liblinear ........\n",
            "[CV]  C=10, l1_ratio=0.2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=10, l1_ratio=0.2, penalty=elasticnet, solver=liblinear ........\n",
            "[CV]  C=10, l1_ratio=0.2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=l1, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.4, penalty=l1, solver=saga, score=0.672, total=  46.1s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=l1, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.4, penalty=l1, solver=saga, score=0.666, total=  27.2s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=l1, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.4, penalty=l1, solver=saga, score=0.654, total=  40.2s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=l1, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.4, penalty=l1, solver=saga, score=0.647, total=  28.7s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=l1, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.4, penalty=l1, solver=saga, score=0.658, total=  27.2s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=l1, solver=liblinear ................\n",
            "[CV]  C=10, l1_ratio=0.4, penalty=l1, solver=liblinear, score=0.672, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=l1, solver=liblinear ................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.4, penalty=l1, solver=liblinear, score=0.666, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=l1, solver=liblinear ................\n",
            "[CV]  C=10, l1_ratio=0.4, penalty=l1, solver=liblinear, score=0.654, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=l1, solver=liblinear ................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.4, penalty=l1, solver=liblinear, score=0.647, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=l1, solver=liblinear ................\n",
            "[CV]  C=10, l1_ratio=0.4, penalty=l1, solver=liblinear, score=0.659, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=l2, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.4, penalty=l2, solver=saga, score=0.672, total=  35.5s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=l2, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.4, penalty=l2, solver=saga, score=0.666, total=  21.5s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=l2, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.4, penalty=l2, solver=saga, score=0.654, total=  32.0s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=l2, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.4, penalty=l2, solver=saga, score=0.647, total=  22.5s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=l2, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.4, penalty=l2, solver=saga, score=0.658, total=  21.6s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=l2, solver=liblinear ................\n",
            "[CV]  C=10, l1_ratio=0.4, penalty=l2, solver=liblinear, score=0.672, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=l2, solver=liblinear ................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.4, penalty=l2, solver=liblinear, score=0.666, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=l2, solver=liblinear ................\n",
            "[CV]  C=10, l1_ratio=0.4, penalty=l2, solver=liblinear, score=0.654, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=l2, solver=liblinear ................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.4, penalty=l2, solver=liblinear, score=0.647, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=l2, solver=liblinear ................\n",
            "[CV]  C=10, l1_ratio=0.4, penalty=l2, solver=liblinear, score=0.659, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=elasticnet, solver=saga .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.4, penalty=elasticnet, solver=saga, score=0.672, total=  46.4s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=elasticnet, solver=saga .............\n",
            "[CV]  C=10, l1_ratio=0.4, penalty=elasticnet, solver=saga, score=0.666, total=  28.4s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=elasticnet, solver=saga .............\n",
            "[CV]  C=10, l1_ratio=0.4, penalty=elasticnet, solver=saga, score=0.654, total=  41.5s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=elasticnet, solver=saga .............\n",
            "[CV]  C=10, l1_ratio=0.4, penalty=elasticnet, solver=saga, score=0.647, total=  29.5s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=elasticnet, solver=saga .............\n",
            "[CV]  C=10, l1_ratio=0.4, penalty=elasticnet, solver=saga, score=0.658, total=  28.4s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=elasticnet, solver=liblinear ........\n",
            "[CV]  C=10, l1_ratio=0.4, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=elasticnet, solver=liblinear ........\n",
            "[CV]  C=10, l1_ratio=0.4, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=elasticnet, solver=liblinear ........\n",
            "[CV]  C=10, l1_ratio=0.4, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=elasticnet, solver=liblinear ........\n",
            "[CV]  C=10, l1_ratio=0.4, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=10, l1_ratio=0.4, penalty=elasticnet, solver=liblinear ........\n",
            "[CV]  C=10, l1_ratio=0.4, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=l1, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.5, penalty=l1, solver=saga, score=0.672, total=  46.3s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=l1, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.5, penalty=l1, solver=saga, score=0.666, total=  27.5s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=l1, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.5, penalty=l1, solver=saga, score=0.654, total=  40.5s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=l1, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.5, penalty=l1, solver=saga, score=0.647, total=  28.3s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=l1, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.5, penalty=l1, solver=saga, score=0.658, total=  27.3s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=l1, solver=liblinear ................\n",
            "[CV]  C=10, l1_ratio=0.5, penalty=l1, solver=liblinear, score=0.672, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=l1, solver=liblinear ................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.5, penalty=l1, solver=liblinear, score=0.666, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=l1, solver=liblinear ................\n",
            "[CV]  C=10, l1_ratio=0.5, penalty=l1, solver=liblinear, score=0.654, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=l1, solver=liblinear ................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.5, penalty=l1, solver=liblinear, score=0.647, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=l1, solver=liblinear ................\n",
            "[CV]  C=10, l1_ratio=0.5, penalty=l1, solver=liblinear, score=0.659, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=l2, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.5, penalty=l2, solver=saga, score=0.672, total=  35.4s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=l2, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.5, penalty=l2, solver=saga, score=0.666, total=  21.6s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=l2, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.5, penalty=l2, solver=saga, score=0.654, total=  31.9s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=l2, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.5, penalty=l2, solver=saga, score=0.647, total=  22.5s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=l2, solver=saga .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.5, penalty=l2, solver=saga, score=0.658, total=  21.8s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=l2, solver=liblinear ................\n",
            "[CV]  C=10, l1_ratio=0.5, penalty=l2, solver=liblinear, score=0.672, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=l2, solver=liblinear ................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.5, penalty=l2, solver=liblinear, score=0.666, total=   0.1s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=l2, solver=liblinear ................\n",
            "[CV]  C=10, l1_ratio=0.5, penalty=l2, solver=liblinear, score=0.654, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=l2, solver=liblinear ................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.5, penalty=l2, solver=liblinear, score=0.647, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=l2, solver=liblinear ................\n",
            "[CV]  C=10, l1_ratio=0.5, penalty=l2, solver=liblinear, score=0.659, total=   0.2s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga, score=0.672, total=  46.6s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga .............\n",
            "[CV]  C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga, score=0.666, total=  28.3s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga .............\n",
            "[CV]  C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga, score=0.654, total=  41.2s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga .............\n",
            "[CV]  C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga, score=0.647, total=  29.0s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga .............\n",
            "[CV]  C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga, score=0.658, total=  28.0s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=elasticnet, solver=liblinear ........\n",
            "[CV]  C=10, l1_ratio=0.5, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=elasticnet, solver=liblinear ........\n",
            "[CV]  C=10, l1_ratio=0.5, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=elasticnet, solver=liblinear ........\n",
            "[CV]  C=10, l1_ratio=0.5, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=elasticnet, solver=liblinear ........\n",
            "[CV]  C=10, l1_ratio=0.5, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
            "[CV] C=10, l1_ratio=0.5, penalty=elasticnet, solver=liblinear ........\n",
            "[CV]  C=10, l1_ratio=0.5, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "  FitFailedWarning)\n",
            "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed: 44.5min finished\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=50000, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [0.01, 0.1, 1, 10], 'l1_ratio': [0.2, 0.4, 0.5],\n",
              "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
              "                         'solver': ['saga', 'liblinear']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPhnYxVaHP8w",
        "outputId": "6f9b09bc-0c8d-4e70-b4db-7c7917c3e261"
      },
      "source": [
        "print(grid_logreg.best_params_)\n",
        "print(grid_logreg.best_estimator_)\n",
        "print(grid_logreg.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'C': 0.01, 'l1_ratio': 0.2, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=0.2, max_iter=50000,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "0.6612379807692308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGESLH1FHlPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fb09b00-9bfe-40da-dfe1-1484d13d0440"
      },
      "source": [
        "logreg = LogisticRegression(C = 0.01, l1_ratio = 0.2, penalty = 'l2', solver = 'liblinear', max_iter = 50000)\n",
        "logreg.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=0.2, max_iter=50000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsPgDmZwNcfJ",
        "outputId": "12e78385-8d65-4880-fc4a-873cb40366df"
      },
      "source": [
        "print(logreg.score(X_train, y_train))\n",
        "print(logreg.score(X_test, y_test))\n",
        "print(precision_score(logreg.predict(X_test), y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.66328125\n",
            "0.6721153846153847\n",
            "0.6000971817298348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qhBfK10vXd2",
        "outputId": "7bd10411-7899-4544-93e4-dbe80be6d4d9"
      },
      "source": [
        "##Now doing the prediction with the help of adaboost classifiers\n",
        "adaboost_grid = {'n_estimators' : [100, 150, 200, 250],\n",
        "                 'algorithm' : ['SAMME.R', 'SAMME'],\n",
        "                 'learning_rate' : [0.2, 0.5, 0.8]}\n",
        "\n",
        "grid_clf = GridSearchCV(AdaBoostClassifier(DecisionTreeClassifier(max_depth = 1)), adaboost_grid, refit = True, verbose = 4)\n",
        "grid_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.2, n_estimators=100 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=0.2, n_estimators=100, score=0.789, total=   1.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.2, n_estimators=100 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=0.2, n_estimators=100, score=0.779, total=   1.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.2, n_estimators=100 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=0.2, n_estimators=100, score=0.765, total=   1.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.2, n_estimators=100 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=0.2, n_estimators=100, score=0.754, total=   1.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.2, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.2, n_estimators=100, score=0.776, total=   1.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.2, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.2, n_estimators=150, score=0.798, total=   2.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.2, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.2, n_estimators=150, score=0.789, total=   2.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.2, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.2, n_estimators=150, score=0.783, total=   2.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.2, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.2, n_estimators=150, score=0.763, total=   2.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.2, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.2, n_estimators=150, score=0.790, total=   2.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.2, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.2, n_estimators=200, score=0.808, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.2, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.2, n_estimators=200, score=0.793, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.2, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.2, n_estimators=200, score=0.787, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.2, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.2, n_estimators=200, score=0.768, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.2, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.2, n_estimators=200, score=0.798, total=   3.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.2, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.2, n_estimators=250, score=0.812, total=   4.5s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.2, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.2, n_estimators=250, score=0.803, total=   4.4s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.2, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.2, n_estimators=250, score=0.790, total=   4.5s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.2, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.2, n_estimators=250, score=0.773, total=   4.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.2, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.2, n_estimators=250, score=0.801, total=   4.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, score=0.816, total=   1.9s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, score=0.804, total=   1.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, score=0.791, total=   1.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, score=0.777, total=   1.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, score=0.804, total=   1.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=150, score=0.822, total=   2.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=150, score=0.812, total=   2.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=150, score=0.803, total=   2.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=150, score=0.787, total=   2.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=150, score=0.815, total=   2.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=200, score=0.828, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=200, score=0.817, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=200, score=0.812, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=200, score=0.795, total=   3.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=200, score=0.813, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=250, score=0.834, total=   4.5s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=250, score=0.824, total=   4.5s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=250, score=0.817, total=   4.5s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=250, score=0.797, total=   4.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=250, score=0.822, total=   4.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.8, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.8, n_estimators=100, score=0.829, total=   1.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.8, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.8, n_estimators=100, score=0.814, total=   1.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.8, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.8, n_estimators=100, score=0.803, total=   1.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.8, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.8, n_estimators=100, score=0.792, total=   1.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.8, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.8, n_estimators=100, score=0.811, total=   1.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.8, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.8, n_estimators=150, score=0.833, total=   2.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.8, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.8, n_estimators=150, score=0.822, total=   2.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.8, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.8, n_estimators=150, score=0.817, total=   2.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.8, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.8, n_estimators=150, score=0.798, total=   2.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.8, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.8, n_estimators=150, score=0.817, total=   2.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.8, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.8, n_estimators=200, score=0.838, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.8, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.8, n_estimators=200, score=0.832, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.8, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.8, n_estimators=200, score=0.821, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.8, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.8, n_estimators=200, score=0.809, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.8, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.8, n_estimators=200, score=0.820, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.8, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.8, n_estimators=250, score=0.842, total=   4.5s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.8, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.8, n_estimators=250, score=0.837, total=   4.5s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.8, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.8, n_estimators=250, score=0.825, total=   4.5s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.8, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.8, n_estimators=250, score=0.810, total=   4.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.8, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.8, n_estimators=250, score=0.827, total=   4.5s\n",
            "[CV] algorithm=SAMME, learning_rate=0.2, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.2, n_estimators=100, score=0.701, total=   1.6s\n",
            "[CV] algorithm=SAMME, learning_rate=0.2, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.2, n_estimators=100, score=0.698, total=   1.6s\n",
            "[CV] algorithm=SAMME, learning_rate=0.2, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.2, n_estimators=100, score=0.687, total=   1.6s\n",
            "[CV] algorithm=SAMME, learning_rate=0.2, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.2, n_estimators=100, score=0.679, total=   1.6s\n",
            "[CV] algorithm=SAMME, learning_rate=0.2, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.2, n_estimators=100, score=0.698, total=   1.6s\n",
            "[CV] algorithm=SAMME, learning_rate=0.2, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.2, n_estimators=150, score=0.701, total=   2.4s\n",
            "[CV] algorithm=SAMME, learning_rate=0.2, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.2, n_estimators=150, score=0.698, total=   2.3s\n",
            "[CV] algorithm=SAMME, learning_rate=0.2, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.2, n_estimators=150, score=0.687, total=   2.4s\n",
            "[CV] algorithm=SAMME, learning_rate=0.2, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.2, n_estimators=150, score=0.679, total=   2.4s\n",
            "[CV] algorithm=SAMME, learning_rate=0.2, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.2, n_estimators=150, score=0.698, total=   2.4s\n",
            "[CV] algorithm=SAMME, learning_rate=0.2, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.2, n_estimators=200, score=0.701, total=   3.1s\n",
            "[CV] algorithm=SAMME, learning_rate=0.2, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.2, n_estimators=200, score=0.700, total=   3.1s\n",
            "[CV] algorithm=SAMME, learning_rate=0.2, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.2, n_estimators=200, score=0.687, total=   3.1s\n",
            "[CV] algorithm=SAMME, learning_rate=0.2, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.2, n_estimators=200, score=0.683, total=   3.2s\n",
            "[CV] algorithm=SAMME, learning_rate=0.2, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.2, n_estimators=200, score=0.698, total=   3.2s\n",
            "[CV] algorithm=SAMME, learning_rate=0.2, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.2, n_estimators=250, score=0.707, total=   4.0s\n",
            "[CV] algorithm=SAMME, learning_rate=0.2, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.2, n_estimators=250, score=0.706, total=   3.9s\n",
            "[CV] algorithm=SAMME, learning_rate=0.2, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.2, n_estimators=250, score=0.688, total=   4.0s\n",
            "[CV] algorithm=SAMME, learning_rate=0.2, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.2, n_estimators=250, score=0.689, total=   3.9s\n",
            "[CV] algorithm=SAMME, learning_rate=0.2, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.2, n_estimators=250, score=0.703, total=   4.0s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=100, score=0.709, total=   1.6s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=100, score=0.711, total=   1.6s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=100, score=0.693, total=   1.6s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=100, score=0.688, total=   1.6s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=100, score=0.709, total=   1.6s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=150, score=0.713, total=   2.4s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=150, score=0.724, total=   2.4s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=150, score=0.701, total=   2.4s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=150, score=0.697, total=   2.4s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=150, score=0.717, total=   2.4s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=200, score=0.721, total=   3.2s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=200, score=0.726, total=   3.1s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=200, score=0.706, total=   3.2s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=200, score=0.702, total=   3.2s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=200, score=0.726, total=   3.2s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=250, score=0.730, total=   4.0s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=250, score=0.733, total=   3.9s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=250, score=0.714, total=   3.9s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=250, score=0.710, total=   4.0s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=250, score=0.734, total=   4.0s\n",
            "[CV] algorithm=SAMME, learning_rate=0.8, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.8, n_estimators=100, score=0.729, total=   1.6s\n",
            "[CV] algorithm=SAMME, learning_rate=0.8, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.8, n_estimators=100, score=0.724, total=   1.6s\n",
            "[CV] algorithm=SAMME, learning_rate=0.8, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.8, n_estimators=100, score=0.720, total=   1.6s\n",
            "[CV] algorithm=SAMME, learning_rate=0.8, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.8, n_estimators=100, score=0.707, total=   1.6s\n",
            "[CV] algorithm=SAMME, learning_rate=0.8, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.8, n_estimators=100, score=0.733, total=   1.6s\n",
            "[CV] algorithm=SAMME, learning_rate=0.8, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.8, n_estimators=150, score=0.751, total=   2.4s\n",
            "[CV] algorithm=SAMME, learning_rate=0.8, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.8, n_estimators=150, score=0.742, total=   2.4s\n",
            "[CV] algorithm=SAMME, learning_rate=0.8, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.8, n_estimators=150, score=0.735, total=   2.4s\n",
            "[CV] algorithm=SAMME, learning_rate=0.8, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.8, n_estimators=150, score=0.725, total=   2.4s\n",
            "[CV] algorithm=SAMME, learning_rate=0.8, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.8, n_estimators=150, score=0.744, total=   2.4s\n",
            "[CV] algorithm=SAMME, learning_rate=0.8, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.8, n_estimators=200, score=0.760, total=   3.2s\n",
            "[CV] algorithm=SAMME, learning_rate=0.8, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.8, n_estimators=200, score=0.747, total=   3.1s\n",
            "[CV] algorithm=SAMME, learning_rate=0.8, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.8, n_estimators=200, score=0.749, total=   3.2s\n",
            "[CV] algorithm=SAMME, learning_rate=0.8, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.8, n_estimators=200, score=0.733, total=   3.2s\n",
            "[CV] algorithm=SAMME, learning_rate=0.8, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.8, n_estimators=200, score=0.753, total=   3.2s\n",
            "[CV] algorithm=SAMME, learning_rate=0.8, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.8, n_estimators=250, score=0.773, total=   4.0s\n",
            "[CV] algorithm=SAMME, learning_rate=0.8, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.8, n_estimators=250, score=0.757, total=   3.9s\n",
            "[CV] algorithm=SAMME, learning_rate=0.8, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.8, n_estimators=250, score=0.752, total=   3.9s\n",
            "[CV] algorithm=SAMME, learning_rate=0.8, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.8, n_estimators=250, score=0.743, total=   4.0s\n",
            "[CV] algorithm=SAMME, learning_rate=0.8, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.8, n_estimators=250, score=0.761, total=   4.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  5.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
              "                                          base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
              "                                                                                class_weight=None,\n",
              "                                                                                criterion='gini',\n",
              "                                                                                max_depth=1,\n",
              "                                                                                max_features=None,\n",
              "                                                                                max_leaf_nodes=None,\n",
              "                                                                                min_impurity_decrease=0.0,\n",
              "                                                                                min_impurity_split=None,\n",
              "                                                                                min_samples_leaf=1,\n",
              "                                                                                min_samples_split=2,\n",
              "                                                                                min_weight_fraction_leaf=0.0,\n",
              "                                                                                presort='deprecated',\n",
              "                                                                                random_state=None,\n",
              "                                                                                splitter='best'),\n",
              "                                          learning_rate=1.0, n_estimators=50,\n",
              "                                          random_state=None),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'algorithm': ['SAMME.R', 'SAMME'],\n",
              "                         'learning_rate': [0.2, 0.5, 0.8],\n",
              "                         'n_estimators': [100, 150, 200, 250]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42aKY7mN2n20",
        "outputId": "b74af005-1e4f-4b30-87e7-f6edb11edfd8"
      },
      "source": [
        "print(grid_clf.best_estimator_)\n",
        "print(grid_clf.best_params_)\n",
        "print(grid_clf.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AdaBoostClassifier(algorithm='SAMME.R',\n",
            "                   base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
            "                                                         class_weight=None,\n",
            "                                                         criterion='gini',\n",
            "                                                         max_depth=1,\n",
            "                                                         max_features=None,\n",
            "                                                         max_leaf_nodes=None,\n",
            "                                                         min_impurity_decrease=0.0,\n",
            "                                                         min_impurity_split=None,\n",
            "                                                         min_samples_leaf=1,\n",
            "                                                         min_samples_split=2,\n",
            "                                                         min_weight_fraction_leaf=0.0,\n",
            "                                                         presort='deprecated',\n",
            "                                                         random_state=None,\n",
            "                                                         splitter='best'),\n",
            "                   learning_rate=0.8, n_estimators=250, random_state=None)\n",
            "{'algorithm': 'SAMME.R', 'learning_rate': 0.8, 'n_estimators': 250}\n",
            "0.828125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lvtqxLb2zG9",
        "outputId": "cf474cbe-d506-4372-b522-c20becdd8b24"
      },
      "source": [
        "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth = 1), algorithm = 'SAMME.R', learning_rate = 0.8, n_estimators = 250)\n",
        "ada_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(algorithm='SAMME.R',\n",
              "                   base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
              "                                                         class_weight=None,\n",
              "                                                         criterion='gini',\n",
              "                                                         max_depth=1,\n",
              "                                                         max_features=None,\n",
              "                                                         max_leaf_nodes=None,\n",
              "                                                         min_impurity_decrease=0.0,\n",
              "                                                         min_impurity_split=None,\n",
              "                                                         min_samples_leaf=1,\n",
              "                                                         min_samples_split=2,\n",
              "                                                         min_weight_fraction_leaf=0.0,\n",
              "                                                         presort='deprecated',\n",
              "                                                         random_state=None,\n",
              "                                                         splitter='best'),\n",
              "                   learning_rate=0.8, n_estimators=250, random_state=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKMFAtep3ONq",
        "outputId": "e5cb7169-c763-4926-af94-7ed7720caa8e"
      },
      "source": [
        "print(ada_clf.score(X_train, y_train))\n",
        "print(ada_clf.score(X_test, y_test))\n",
        "print(precision_score(ada_clf.predict(X_test), y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8364783653846154\n",
            "0.833173076923077\n",
            "0.8440233236151603\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fvhmNXi4vrg",
        "outputId": "61cc710b-288a-410b-83f4-5122fee435ec"
      },
      "source": [
        "rf_grid = {'n_estimators' : [200, 250, 300, 350],\n",
        "           'max_depth' : [16, 20, 24],\n",
        "           'criterion' : ['gini', 'entropy']}\n",
        "\n",
        "rf_grid_clf = GridSearchCV(RandomForestClassifier(bootstrap = True, oob_score = True), rf_grid, refit = True, verbose = 4)\n",
        "rf_grid_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "[CV] criterion=gini, max_depth=16, n_estimators=200 ..................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=gini, max_depth=16, n_estimators=200, score=0.841, total=   3.8s\n",
            "[CV] criterion=gini, max_depth=16, n_estimators=200 ..................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=gini, max_depth=16, n_estimators=200, score=0.831, total=   3.7s\n",
            "[CV] criterion=gini, max_depth=16, n_estimators=200 ..................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    7.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=gini, max_depth=16, n_estimators=200, score=0.818, total=   3.7s\n",
            "[CV] criterion=gini, max_depth=16, n_estimators=200 ..................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   11.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=gini, max_depth=16, n_estimators=200, score=0.800, total=   3.8s\n",
            "[CV] criterion=gini, max_depth=16, n_estimators=200 ..................\n",
            "[CV]  criterion=gini, max_depth=16, n_estimators=200, score=0.828, total=   3.7s\n",
            "[CV] criterion=gini, max_depth=16, n_estimators=250 ..................\n",
            "[CV]  criterion=gini, max_depth=16, n_estimators=250, score=0.837, total=   4.7s\n",
            "[CV] criterion=gini, max_depth=16, n_estimators=250 ..................\n",
            "[CV]  criterion=gini, max_depth=16, n_estimators=250, score=0.833, total=   4.6s\n",
            "[CV] criterion=gini, max_depth=16, n_estimators=250 ..................\n",
            "[CV]  criterion=gini, max_depth=16, n_estimators=250, score=0.822, total=   4.7s\n",
            "[CV] criterion=gini, max_depth=16, n_estimators=250 ..................\n",
            "[CV]  criterion=gini, max_depth=16, n_estimators=250, score=0.803, total=   4.7s\n",
            "[CV] criterion=gini, max_depth=16, n_estimators=250 ..................\n",
            "[CV]  criterion=gini, max_depth=16, n_estimators=250, score=0.826, total=   4.7s\n",
            "[CV] criterion=gini, max_depth=16, n_estimators=300 ..................\n",
            "[CV]  criterion=gini, max_depth=16, n_estimators=300, score=0.845, total=   5.6s\n",
            "[CV] criterion=gini, max_depth=16, n_estimators=300 ..................\n",
            "[CV]  criterion=gini, max_depth=16, n_estimators=300, score=0.832, total=   5.5s\n",
            "[CV] criterion=gini, max_depth=16, n_estimators=300 ..................\n",
            "[CV]  criterion=gini, max_depth=16, n_estimators=300, score=0.825, total=   5.5s\n",
            "[CV] criterion=gini, max_depth=16, n_estimators=300 ..................\n",
            "[CV]  criterion=gini, max_depth=16, n_estimators=300, score=0.803, total=   5.6s\n",
            "[CV] criterion=gini, max_depth=16, n_estimators=300 ..................\n",
            "[CV]  criterion=gini, max_depth=16, n_estimators=300, score=0.826, total=   5.6s\n",
            "[CV] criterion=gini, max_depth=16, n_estimators=350 ..................\n",
            "[CV]  criterion=gini, max_depth=16, n_estimators=350, score=0.839, total=   6.5s\n",
            "[CV] criterion=gini, max_depth=16, n_estimators=350 ..................\n",
            "[CV]  criterion=gini, max_depth=16, n_estimators=350, score=0.830, total=   6.5s\n",
            "[CV] criterion=gini, max_depth=16, n_estimators=350 ..................\n",
            "[CV]  criterion=gini, max_depth=16, n_estimators=350, score=0.822, total=   6.4s\n",
            "[CV] criterion=gini, max_depth=16, n_estimators=350 ..................\n",
            "[CV]  criterion=gini, max_depth=16, n_estimators=350, score=0.804, total=   6.4s\n",
            "[CV] criterion=gini, max_depth=16, n_estimators=350 ..................\n",
            "[CV]  criterion=gini, max_depth=16, n_estimators=350, score=0.828, total=   6.4s\n",
            "[CV] criterion=gini, max_depth=20, n_estimators=200 ..................\n",
            "[CV]  criterion=gini, max_depth=20, n_estimators=200, score=0.846, total=   4.4s\n",
            "[CV] criterion=gini, max_depth=20, n_estimators=200 ..................\n",
            "[CV]  criterion=gini, max_depth=20, n_estimators=200, score=0.839, total=   4.2s\n",
            "[CV] criterion=gini, max_depth=20, n_estimators=200 ..................\n",
            "[CV]  criterion=gini, max_depth=20, n_estimators=200, score=0.829, total=   4.2s\n",
            "[CV] criterion=gini, max_depth=20, n_estimators=200 ..................\n",
            "[CV]  criterion=gini, max_depth=20, n_estimators=200, score=0.818, total=   4.1s\n",
            "[CV] criterion=gini, max_depth=20, n_estimators=200 ..................\n",
            "[CV]  criterion=gini, max_depth=20, n_estimators=200, score=0.835, total=   4.2s\n",
            "[CV] criterion=gini, max_depth=20, n_estimators=250 ..................\n",
            "[CV]  criterion=gini, max_depth=20, n_estimators=250, score=0.845, total=   5.1s\n",
            "[CV] criterion=gini, max_depth=20, n_estimators=250 ..................\n",
            "[CV]  criterion=gini, max_depth=20, n_estimators=250, score=0.841, total=   5.2s\n",
            "[CV] criterion=gini, max_depth=20, n_estimators=250 ..................\n",
            "[CV]  criterion=gini, max_depth=20, n_estimators=250, score=0.825, total=   5.2s\n",
            "[CV] criterion=gini, max_depth=20, n_estimators=250 ..................\n",
            "[CV]  criterion=gini, max_depth=20, n_estimators=250, score=0.816, total=   5.3s\n",
            "[CV] criterion=gini, max_depth=20, n_estimators=250 ..................\n",
            "[CV]  criterion=gini, max_depth=20, n_estimators=250, score=0.829, total=   5.2s\n",
            "[CV] criterion=gini, max_depth=20, n_estimators=300 ..................\n",
            "[CV]  criterion=gini, max_depth=20, n_estimators=300, score=0.850, total=   6.3s\n",
            "[CV] criterion=gini, max_depth=20, n_estimators=300 ..................\n",
            "[CV]  criterion=gini, max_depth=20, n_estimators=300, score=0.842, total=   6.2s\n",
            "[CV] criterion=gini, max_depth=20, n_estimators=300 ..................\n",
            "[CV]  criterion=gini, max_depth=20, n_estimators=300, score=0.828, total=   6.3s\n",
            "[CV] criterion=gini, max_depth=20, n_estimators=300 ..................\n",
            "[CV]  criterion=gini, max_depth=20, n_estimators=300, score=0.813, total=   6.3s\n",
            "[CV] criterion=gini, max_depth=20, n_estimators=300 ..................\n",
            "[CV]  criterion=gini, max_depth=20, n_estimators=300, score=0.836, total=   6.3s\n",
            "[CV] criterion=gini, max_depth=20, n_estimators=350 ..................\n",
            "[CV]  criterion=gini, max_depth=20, n_estimators=350, score=0.846, total=   7.4s\n",
            "[CV] criterion=gini, max_depth=20, n_estimators=350 ..................\n",
            "[CV]  criterion=gini, max_depth=20, n_estimators=350, score=0.838, total=   7.4s\n",
            "[CV] criterion=gini, max_depth=20, n_estimators=350 ..................\n",
            "[CV]  criterion=gini, max_depth=20, n_estimators=350, score=0.828, total=   7.4s\n",
            "[CV] criterion=gini, max_depth=20, n_estimators=350 ..................\n",
            "[CV]  criterion=gini, max_depth=20, n_estimators=350, score=0.809, total=   7.2s\n",
            "[CV] criterion=gini, max_depth=20, n_estimators=350 ..................\n",
            "[CV]  criterion=gini, max_depth=20, n_estimators=350, score=0.831, total=   7.2s\n",
            "[CV] criterion=gini, max_depth=24, n_estimators=200 ..................\n",
            "[CV]  criterion=gini, max_depth=24, n_estimators=200, score=0.842, total=   4.5s\n",
            "[CV] criterion=gini, max_depth=24, n_estimators=200 ..................\n",
            "[CV]  criterion=gini, max_depth=24, n_estimators=200, score=0.844, total=   4.5s\n",
            "[CV] criterion=gini, max_depth=24, n_estimators=200 ..................\n",
            "[CV]  criterion=gini, max_depth=24, n_estimators=200, score=0.829, total=   4.4s\n",
            "[CV] criterion=gini, max_depth=24, n_estimators=200 ..................\n",
            "[CV]  criterion=gini, max_depth=24, n_estimators=200, score=0.819, total=   4.4s\n",
            "[CV] criterion=gini, max_depth=24, n_estimators=200 ..................\n",
            "[CV]  criterion=gini, max_depth=24, n_estimators=200, score=0.833, total=   4.4s\n",
            "[CV] criterion=gini, max_depth=24, n_estimators=250 ..................\n",
            "[CV]  criterion=gini, max_depth=24, n_estimators=250, score=0.852, total=   5.5s\n",
            "[CV] criterion=gini, max_depth=24, n_estimators=250 ..................\n",
            "[CV]  criterion=gini, max_depth=24, n_estimators=250, score=0.843, total=   5.5s\n",
            "[CV] criterion=gini, max_depth=24, n_estimators=250 ..................\n",
            "[CV]  criterion=gini, max_depth=24, n_estimators=250, score=0.832, total=   5.6s\n",
            "[CV] criterion=gini, max_depth=24, n_estimators=250 ..................\n",
            "[CV]  criterion=gini, max_depth=24, n_estimators=250, score=0.819, total=   5.6s\n",
            "[CV] criterion=gini, max_depth=24, n_estimators=250 ..................\n",
            "[CV]  criterion=gini, max_depth=24, n_estimators=250, score=0.836, total=   5.8s\n",
            "[CV] criterion=gini, max_depth=24, n_estimators=300 ..................\n",
            "[CV]  criterion=gini, max_depth=24, n_estimators=300, score=0.847, total=   6.7s\n",
            "[CV] criterion=gini, max_depth=24, n_estimators=300 ..................\n",
            "[CV]  criterion=gini, max_depth=24, n_estimators=300, score=0.843, total=   6.7s\n",
            "[CV] criterion=gini, max_depth=24, n_estimators=300 ..................\n",
            "[CV]  criterion=gini, max_depth=24, n_estimators=300, score=0.832, total=   6.8s\n",
            "[CV] criterion=gini, max_depth=24, n_estimators=300 ..................\n",
            "[CV]  criterion=gini, max_depth=24, n_estimators=300, score=0.817, total=   6.6s\n",
            "[CV] criterion=gini, max_depth=24, n_estimators=300 ..................\n",
            "[CV]  criterion=gini, max_depth=24, n_estimators=300, score=0.836, total=   6.7s\n",
            "[CV] criterion=gini, max_depth=24, n_estimators=350 ..................\n",
            "[CV]  criterion=gini, max_depth=24, n_estimators=350, score=0.849, total=   7.8s\n",
            "[CV] criterion=gini, max_depth=24, n_estimators=350 ..................\n",
            "[CV]  criterion=gini, max_depth=24, n_estimators=350, score=0.843, total=   7.7s\n",
            "[CV] criterion=gini, max_depth=24, n_estimators=350 ..................\n",
            "[CV]  criterion=gini, max_depth=24, n_estimators=350, score=0.829, total=   7.8s\n",
            "[CV] criterion=gini, max_depth=24, n_estimators=350 ..................\n",
            "[CV]  criterion=gini, max_depth=24, n_estimators=350, score=0.818, total=   7.7s\n",
            "[CV] criterion=gini, max_depth=24, n_estimators=350 ..................\n",
            "[CV]  criterion=gini, max_depth=24, n_estimators=350, score=0.835, total=   7.9s\n",
            "[CV] criterion=entropy, max_depth=16, n_estimators=200 ...............\n",
            "[CV]  criterion=entropy, max_depth=16, n_estimators=200, score=0.839, total=   4.5s\n",
            "[CV] criterion=entropy, max_depth=16, n_estimators=200 ...............\n",
            "[CV]  criterion=entropy, max_depth=16, n_estimators=200, score=0.830, total=   4.4s\n",
            "[CV] criterion=entropy, max_depth=16, n_estimators=200 ...............\n",
            "[CV]  criterion=entropy, max_depth=16, n_estimators=200, score=0.822, total=   4.5s\n",
            "[CV] criterion=entropy, max_depth=16, n_estimators=200 ...............\n",
            "[CV]  criterion=entropy, max_depth=16, n_estimators=200, score=0.803, total=   4.4s\n",
            "[CV] criterion=entropy, max_depth=16, n_estimators=200 ...............\n",
            "[CV]  criterion=entropy, max_depth=16, n_estimators=200, score=0.828, total=   4.5s\n",
            "[CV] criterion=entropy, max_depth=16, n_estimators=250 ...............\n",
            "[CV]  criterion=entropy, max_depth=16, n_estimators=250, score=0.837, total=   5.5s\n",
            "[CV] criterion=entropy, max_depth=16, n_estimators=250 ...............\n",
            "[CV]  criterion=entropy, max_depth=16, n_estimators=250, score=0.834, total=   5.5s\n",
            "[CV] criterion=entropy, max_depth=16, n_estimators=250 ...............\n",
            "[CV]  criterion=entropy, max_depth=16, n_estimators=250, score=0.820, total=   5.6s\n",
            "[CV] criterion=entropy, max_depth=16, n_estimators=250 ...............\n",
            "[CV]  criterion=entropy, max_depth=16, n_estimators=250, score=0.799, total=   5.6s\n",
            "[CV] criterion=entropy, max_depth=16, n_estimators=250 ...............\n",
            "[CV]  criterion=entropy, max_depth=16, n_estimators=250, score=0.825, total=   5.5s\n",
            "[CV] criterion=entropy, max_depth=16, n_estimators=300 ...............\n",
            "[CV]  criterion=entropy, max_depth=16, n_estimators=300, score=0.838, total=   6.6s\n",
            "[CV] criterion=entropy, max_depth=16, n_estimators=300 ...............\n",
            "[CV]  criterion=entropy, max_depth=16, n_estimators=300, score=0.831, total=   6.6s\n",
            "[CV] criterion=entropy, max_depth=16, n_estimators=300 ...............\n",
            "[CV]  criterion=entropy, max_depth=16, n_estimators=300, score=0.824, total=   6.6s\n",
            "[CV] criterion=entropy, max_depth=16, n_estimators=300 ...............\n",
            "[CV]  criterion=entropy, max_depth=16, n_estimators=300, score=0.803, total=   6.6s\n",
            "[CV] criterion=entropy, max_depth=16, n_estimators=300 ...............\n",
            "[CV]  criterion=entropy, max_depth=16, n_estimators=300, score=0.828, total=   6.6s\n",
            "[CV] criterion=entropy, max_depth=16, n_estimators=350 ...............\n",
            "[CV]  criterion=entropy, max_depth=16, n_estimators=350, score=0.841, total=   7.7s\n",
            "[CV] criterion=entropy, max_depth=16, n_estimators=350 ...............\n",
            "[CV]  criterion=entropy, max_depth=16, n_estimators=350, score=0.833, total=   7.6s\n",
            "[CV] criterion=entropy, max_depth=16, n_estimators=350 ...............\n",
            "[CV]  criterion=entropy, max_depth=16, n_estimators=350, score=0.824, total=   7.7s\n",
            "[CV] criterion=entropy, max_depth=16, n_estimators=350 ...............\n",
            "[CV]  criterion=entropy, max_depth=16, n_estimators=350, score=0.801, total=   7.7s\n",
            "[CV] criterion=entropy, max_depth=16, n_estimators=350 ...............\n",
            "[CV]  criterion=entropy, max_depth=16, n_estimators=350, score=0.829, total=   7.7s\n",
            "[CV] criterion=entropy, max_depth=20, n_estimators=200 ...............\n",
            "[CV]  criterion=entropy, max_depth=20, n_estimators=200, score=0.850, total=   5.2s\n",
            "[CV] criterion=entropy, max_depth=20, n_estimators=200 ...............\n",
            "[CV]  criterion=entropy, max_depth=20, n_estimators=200, score=0.839, total=   5.2s\n",
            "[CV] criterion=entropy, max_depth=20, n_estimators=200 ...............\n",
            "[CV]  criterion=entropy, max_depth=20, n_estimators=200, score=0.829, total=   5.1s\n",
            "[CV] criterion=entropy, max_depth=20, n_estimators=200 ...............\n",
            "[CV]  criterion=entropy, max_depth=20, n_estimators=200, score=0.810, total=   5.1s\n",
            "[CV] criterion=entropy, max_depth=20, n_estimators=200 ...............\n",
            "[CV]  criterion=entropy, max_depth=20, n_estimators=200, score=0.832, total=   5.1s\n",
            "[CV] criterion=entropy, max_depth=20, n_estimators=250 ...............\n",
            "[CV]  criterion=entropy, max_depth=20, n_estimators=250, score=0.844, total=   6.4s\n",
            "[CV] criterion=entropy, max_depth=20, n_estimators=250 ...............\n",
            "[CV]  criterion=entropy, max_depth=20, n_estimators=250, score=0.838, total=   6.4s\n",
            "[CV] criterion=entropy, max_depth=20, n_estimators=250 ...............\n",
            "[CV]  criterion=entropy, max_depth=20, n_estimators=250, score=0.827, total=   6.3s\n",
            "[CV] criterion=entropy, max_depth=20, n_estimators=250 ...............\n",
            "[CV]  criterion=entropy, max_depth=20, n_estimators=250, score=0.812, total=   6.4s\n",
            "[CV] criterion=entropy, max_depth=20, n_estimators=250 ...............\n",
            "[CV]  criterion=entropy, max_depth=20, n_estimators=250, score=0.833, total=   6.4s\n",
            "[CV] criterion=entropy, max_depth=20, n_estimators=300 ...............\n",
            "[CV]  criterion=entropy, max_depth=20, n_estimators=300, score=0.846, total=   8.0s\n",
            "[CV] criterion=entropy, max_depth=20, n_estimators=300 ...............\n",
            "[CV]  criterion=entropy, max_depth=20, n_estimators=300, score=0.839, total=   7.7s\n",
            "[CV] criterion=entropy, max_depth=20, n_estimators=300 ...............\n",
            "[CV]  criterion=entropy, max_depth=20, n_estimators=300, score=0.829, total=   7.8s\n",
            "[CV] criterion=entropy, max_depth=20, n_estimators=300 ...............\n",
            "[CV]  criterion=entropy, max_depth=20, n_estimators=300, score=0.813, total=   7.7s\n",
            "[CV] criterion=entropy, max_depth=20, n_estimators=300 ...............\n",
            "[CV]  criterion=entropy, max_depth=20, n_estimators=300, score=0.835, total=   7.7s\n",
            "[CV] criterion=entropy, max_depth=20, n_estimators=350 ...............\n",
            "[CV]  criterion=entropy, max_depth=20, n_estimators=350, score=0.848, total=   9.0s\n",
            "[CV] criterion=entropy, max_depth=20, n_estimators=350 ...............\n",
            "[CV]  criterion=entropy, max_depth=20, n_estimators=350, score=0.842, total=   9.0s\n",
            "[CV] criterion=entropy, max_depth=20, n_estimators=350 ...............\n",
            "[CV]  criterion=entropy, max_depth=20, n_estimators=350, score=0.826, total=   8.9s\n",
            "[CV] criterion=entropy, max_depth=20, n_estimators=350 ...............\n",
            "[CV]  criterion=entropy, max_depth=20, n_estimators=350, score=0.812, total=   9.1s\n",
            "[CV] criterion=entropy, max_depth=20, n_estimators=350 ...............\n",
            "[CV]  criterion=entropy, max_depth=20, n_estimators=350, score=0.832, total=   8.9s\n",
            "[CV] criterion=entropy, max_depth=24, n_estimators=200 ...............\n",
            "[CV]  criterion=entropy, max_depth=24, n_estimators=200, score=0.850, total=   5.7s\n",
            "[CV] criterion=entropy, max_depth=24, n_estimators=200 ...............\n",
            "[CV]  criterion=entropy, max_depth=24, n_estimators=200, score=0.845, total=   5.6s\n",
            "[CV] criterion=entropy, max_depth=24, n_estimators=200 ...............\n",
            "[CV]  criterion=entropy, max_depth=24, n_estimators=200, score=0.833, total=   5.7s\n",
            "[CV] criterion=entropy, max_depth=24, n_estimators=200 ...............\n",
            "[CV]  criterion=entropy, max_depth=24, n_estimators=200, score=0.818, total=   5.7s\n",
            "[CV] criterion=entropy, max_depth=24, n_estimators=200 ...............\n",
            "[CV]  criterion=entropy, max_depth=24, n_estimators=200, score=0.836, total=   5.6s\n",
            "[CV] criterion=entropy, max_depth=24, n_estimators=250 ...............\n",
            "[CV]  criterion=entropy, max_depth=24, n_estimators=250, score=0.850, total=   7.1s\n",
            "[CV] criterion=entropy, max_depth=24, n_estimators=250 ...............\n",
            "[CV]  criterion=entropy, max_depth=24, n_estimators=250, score=0.844, total=   7.1s\n",
            "[CV] criterion=entropy, max_depth=24, n_estimators=250 ...............\n",
            "[CV]  criterion=entropy, max_depth=24, n_estimators=250, score=0.833, total=   7.2s\n",
            "[CV] criterion=entropy, max_depth=24, n_estimators=250 ...............\n",
            "[CV]  criterion=entropy, max_depth=24, n_estimators=250, score=0.819, total=   7.1s\n",
            "[CV] criterion=entropy, max_depth=24, n_estimators=250 ...............\n",
            "[CV]  criterion=entropy, max_depth=24, n_estimators=250, score=0.836, total=   7.1s\n",
            "[CV] criterion=entropy, max_depth=24, n_estimators=300 ...............\n",
            "[CV]  criterion=entropy, max_depth=24, n_estimators=300, score=0.847, total=   8.6s\n",
            "[CV] criterion=entropy, max_depth=24, n_estimators=300 ...............\n",
            "[CV]  criterion=entropy, max_depth=24, n_estimators=300, score=0.849, total=   8.5s\n",
            "[CV] criterion=entropy, max_depth=24, n_estimators=300 ...............\n",
            "[CV]  criterion=entropy, max_depth=24, n_estimators=300, score=0.832, total=   8.5s\n",
            "[CV] criterion=entropy, max_depth=24, n_estimators=300 ...............\n",
            "[CV]  criterion=entropy, max_depth=24, n_estimators=300, score=0.820, total=   8.5s\n",
            "[CV] criterion=entropy, max_depth=24, n_estimators=300 ...............\n",
            "[CV]  criterion=entropy, max_depth=24, n_estimators=300, score=0.835, total=   8.7s\n",
            "[CV] criterion=entropy, max_depth=24, n_estimators=350 ...............\n",
            "[CV]  criterion=entropy, max_depth=24, n_estimators=350, score=0.850, total=  10.6s\n",
            "[CV] criterion=entropy, max_depth=24, n_estimators=350 ...............\n",
            "[CV]  criterion=entropy, max_depth=24, n_estimators=350, score=0.845, total=   9.9s\n",
            "[CV] criterion=entropy, max_depth=24, n_estimators=350 ...............\n",
            "[CV]  criterion=entropy, max_depth=24, n_estimators=350, score=0.831, total=  10.0s\n",
            "[CV] criterion=entropy, max_depth=24, n_estimators=350 ...............\n",
            "[CV]  criterion=entropy, max_depth=24, n_estimators=350, score=0.819, total=   9.9s\n",
            "[CV] criterion=entropy, max_depth=24, n_estimators=350 ...............\n",
            "[CV]  criterion=entropy, max_depth=24, n_estimators=350, score=0.832, total=  10.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed: 12.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=True, random_state=None,\n",
              "                                              verbose=0, warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'max_depth': [16, 20, 24],\n",
              "                         'n_estimators': [200, 250, 300, 350]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-Jcn9HS7xzu",
        "outputId": "5236a474-f21f-47fd-ce22-a3241ae59558"
      },
      "source": [
        "print(rf_grid_clf.best_params_)\n",
        "print(rf_grid_clf.best_estimator_)\n",
        "print(rf_grid_clf.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'criterion': 'entropy', 'max_depth': 24, 'n_estimators': 300}\n",
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='entropy', max_depth=24, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
            "                       n_jobs=None, oob_score=True, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "0.8365985576923076\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsrV5VJ_-59c",
        "outputId": "14676b5b-2b57-4539-d71a-4817fc19a50d"
      },
      "source": [
        "rf_clf = RandomForestClassifier(criterion = 'entropy', max_depth = 24, n_estimators = 300)\n",
        "rf_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='entropy', max_depth=24, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbRxFWyE_aai",
        "outputId": "a4d89ad6-fc19-4528-9315-bb36d3a1292f"
      },
      "source": [
        "print(rf_clf.score(X_train, y_train))\n",
        "print(rf_clf.score(X_test, y_test))\n",
        "print(precision_score(rf_clf.predict(X_test), y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9907451923076923\n",
            "0.8444711538461539\n",
            "0.8629737609329446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asc6knAB_657",
        "outputId": "95d72df8-61e4-45a0-e784-e98abb064dde"
      },
      "source": [
        "xgb_clf = XGBClassifier(learning_rate=0.8)\n",
        "xgb_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.8, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQxo_8wTAXrX",
        "outputId": "5792e7fe-28b8-42c9-e441-94d9b58fbb65"
      },
      "source": [
        "print(xgb_clf.score(X_train, y_train))\n",
        "print(xgb_clf.score(X_test, y_test))\n",
        "print(precision_score(xgb_clf.predict(X_test), y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9141225961538462\n",
            "0.8769230769230769\n",
            "0.892128279883382\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5erXpPvON-2"
      },
      "source": [
        "test_doc = test['clean_total']\n",
        "test_df = tf_idf_matrix(test_doc)\n",
        "\n",
        "## Now to create the dataset upon which predictions will be done."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcBVLHEKOzFo"
      },
      "source": [
        "lst = []\n",
        "for k in range(1, 5201): \n",
        "  x = test_df[k].where(test_df[k].values > 0.0)\n",
        "  x.fillna(0.0, inplace = True)\n",
        "  y = []\n",
        "  for i in x:\n",
        "    if i > 0.0:\n",
        "      y.append(i)\n",
        "\n",
        "  lst.append(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "LUGLbNDnPUtg",
        "outputId": "d507619c-8f79-4288-f84c-79ede44a5f08"
      },
      "source": [
        "df_test = pd.DataFrame(lst, columns = [i for i in range(1, 26)])\n",
        "df_test.fillna(0.0, inplace = True)\n",
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.863459</td>\n",
              "      <td>2.114113</td>\n",
              "      <td>8.863459</td>\n",
              "      <td>7.477165</td>\n",
              "      <td>8.863459</td>\n",
              "      <td>8.457994</td>\n",
              "      <td>8.863459</td>\n",
              "      <td>6.122619</td>\n",
              "      <td>8.863459</td>\n",
              "      <td>2.788113</td>\n",
              "      <td>7.359382</td>\n",
              "      <td>2.183860</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.560874</td>\n",
              "      <td>6.560874</td>\n",
              "      <td>6.917549</td>\n",
              "      <td>5.187158</td>\n",
              "      <td>6.378552</td>\n",
              "      <td>6.122619</td>\n",
              "      <td>7.947168</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.024007</td>\n",
              "      <td>6.991657</td>\n",
              "      <td>6.723393</td>\n",
              "      <td>7.254021</td>\n",
              "      <td>5.727965</td>\n",
              "      <td>8.170312</td>\n",
              "      <td>7.947168</td>\n",
              "      <td>8.863459</td>\n",
              "      <td>6.991657</td>\n",
              "      <td>6.666234</td>\n",
              "      <td>6.991657</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.337730</td>\n",
              "      <td>7.158711</td>\n",
              "      <td>7.947168</td>\n",
              "      <td>8.170312</td>\n",
              "      <td>2.114113</td>\n",
              "      <td>8.457994</td>\n",
              "      <td>6.723393</td>\n",
              "      <td>4.720324</td>\n",
              "      <td>6.917549</td>\n",
              "      <td>7.071700</td>\n",
              "      <td>2.183860</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.477165</td>\n",
              "      <td>8.863459</td>\n",
              "      <td>8.457994</td>\n",
              "      <td>6.337730</td>\n",
              "      <td>4.820408</td>\n",
              "      <td>6.421112</td>\n",
              "      <td>5.090698</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5195</th>\n",
              "      <td>8.863459</td>\n",
              "      <td>6.001258</td>\n",
              "      <td>8.863459</td>\n",
              "      <td>6.723393</td>\n",
              "      <td>2.114113</td>\n",
              "      <td>8.863459</td>\n",
              "      <td>8.863459</td>\n",
              "      <td>7.947168</td>\n",
              "      <td>2.183860</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5196</th>\n",
              "      <td>7.158711</td>\n",
              "      <td>5.706459</td>\n",
              "      <td>6.512084</td>\n",
              "      <td>5.397723</td>\n",
              "      <td>8.170312</td>\n",
              "      <td>7.477165</td>\n",
              "      <td>2.114113</td>\n",
              "      <td>7.158711</td>\n",
              "      <td>4.971639</td>\n",
              "      <td>8.170312</td>\n",
              "      <td>6.260769</td>\n",
              "      <td>7.947168</td>\n",
              "      <td>8.170312</td>\n",
              "      <td>8.457994</td>\n",
              "      <td>2.18386</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5197</th>\n",
              "      <td>5.945688</td>\n",
              "      <td>8.863459</td>\n",
              "      <td>6.784017</td>\n",
              "      <td>2.114113</td>\n",
              "      <td>8.170312</td>\n",
              "      <td>6.189310</td>\n",
              "      <td>6.337730</td>\n",
              "      <td>2.183860</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5198</th>\n",
              "      <td>5.919020</td>\n",
              "      <td>7.477165</td>\n",
              "      <td>6.991657</td>\n",
              "      <td>7.947168</td>\n",
              "      <td>5.187158</td>\n",
              "      <td>4.593762</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5199</th>\n",
              "      <td>8.457994</td>\n",
              "      <td>2.114113</td>\n",
              "      <td>8.863459</td>\n",
              "      <td>6.666234</td>\n",
              "      <td>8.863459</td>\n",
              "      <td>7.947168</td>\n",
              "      <td>2.183860</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5200 rows × 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            1         2         3         4         5   ...   21   22   23   24   25\n",
              "0     8.863459  2.114113  8.863459  7.477165  8.863459  ...  0.0  0.0  0.0  0.0  0.0\n",
              "1     6.560874  6.560874  6.917549  5.187158  6.378552  ...  0.0  0.0  0.0  0.0  0.0\n",
              "2     5.024007  6.991657  6.723393  7.254021  5.727965  ...  0.0  0.0  0.0  0.0  0.0\n",
              "3     6.337730  7.158711  7.947168  8.170312  2.114113  ...  0.0  0.0  0.0  0.0  0.0\n",
              "4     7.477165  8.863459  8.457994  6.337730  4.820408  ...  0.0  0.0  0.0  0.0  0.0\n",
              "...        ...       ...       ...       ...       ...  ...  ...  ...  ...  ...  ...\n",
              "5195  8.863459  6.001258  8.863459  6.723393  2.114113  ...  0.0  0.0  0.0  0.0  0.0\n",
              "5196  7.158711  5.706459  6.512084  5.397723  8.170312  ...  0.0  0.0  0.0  0.0  0.0\n",
              "5197  5.945688  8.863459  6.784017  2.114113  8.170312  ...  0.0  0.0  0.0  0.0  0.0\n",
              "5198  5.919020  7.477165  6.991657  7.947168  5.187158  ...  0.0  0.0  0.0  0.0  0.0\n",
              "5199  8.457994  2.114113  8.863459  6.666234  8.863459  ...  0.0  0.0  0.0  0.0  0.0\n",
              "\n",
              "[5200 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "apPVYVunjTAT",
        "outputId": "0c33bb91-fe88-4993-8344-e247e548c6dc"
      },
      "source": [
        "## Now adding more columns to make the test and train dataframes same.\n",
        "\n",
        "for i in range(25, 47):\n",
        "  df_test[i] = 0.0\n",
        "\n",
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.863459</td>\n",
              "      <td>2.114113</td>\n",
              "      <td>8.863459</td>\n",
              "      <td>7.477165</td>\n",
              "      <td>8.863459</td>\n",
              "      <td>8.457994</td>\n",
              "      <td>8.863459</td>\n",
              "      <td>6.122619</td>\n",
              "      <td>8.863459</td>\n",
              "      <td>2.788113</td>\n",
              "      <td>7.359382</td>\n",
              "      <td>2.183860</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.560874</td>\n",
              "      <td>6.560874</td>\n",
              "      <td>6.917549</td>\n",
              "      <td>5.187158</td>\n",
              "      <td>6.378552</td>\n",
              "      <td>6.122619</td>\n",
              "      <td>7.947168</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.024007</td>\n",
              "      <td>6.991657</td>\n",
              "      <td>6.723393</td>\n",
              "      <td>7.254021</td>\n",
              "      <td>5.727965</td>\n",
              "      <td>8.170312</td>\n",
              "      <td>7.947168</td>\n",
              "      <td>8.863459</td>\n",
              "      <td>6.991657</td>\n",
              "      <td>6.666234</td>\n",
              "      <td>6.991657</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.337730</td>\n",
              "      <td>7.158711</td>\n",
              "      <td>7.947168</td>\n",
              "      <td>8.170312</td>\n",
              "      <td>2.114113</td>\n",
              "      <td>8.457994</td>\n",
              "      <td>6.723393</td>\n",
              "      <td>4.720324</td>\n",
              "      <td>6.917549</td>\n",
              "      <td>7.071700</td>\n",
              "      <td>2.183860</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.477165</td>\n",
              "      <td>8.863459</td>\n",
              "      <td>8.457994</td>\n",
              "      <td>6.337730</td>\n",
              "      <td>4.820408</td>\n",
              "      <td>6.421112</td>\n",
              "      <td>5.090698</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5195</th>\n",
              "      <td>8.863459</td>\n",
              "      <td>6.001258</td>\n",
              "      <td>8.863459</td>\n",
              "      <td>6.723393</td>\n",
              "      <td>2.114113</td>\n",
              "      <td>8.863459</td>\n",
              "      <td>8.863459</td>\n",
              "      <td>7.947168</td>\n",
              "      <td>2.183860</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5196</th>\n",
              "      <td>7.158711</td>\n",
              "      <td>5.706459</td>\n",
              "      <td>6.512084</td>\n",
              "      <td>5.397723</td>\n",
              "      <td>8.170312</td>\n",
              "      <td>7.477165</td>\n",
              "      <td>2.114113</td>\n",
              "      <td>7.158711</td>\n",
              "      <td>4.971639</td>\n",
              "      <td>8.170312</td>\n",
              "      <td>6.260769</td>\n",
              "      <td>7.947168</td>\n",
              "      <td>8.170312</td>\n",
              "      <td>8.457994</td>\n",
              "      <td>2.18386</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5197</th>\n",
              "      <td>5.945688</td>\n",
              "      <td>8.863459</td>\n",
              "      <td>6.784017</td>\n",
              "      <td>2.114113</td>\n",
              "      <td>8.170312</td>\n",
              "      <td>6.189310</td>\n",
              "      <td>6.337730</td>\n",
              "      <td>2.183860</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5198</th>\n",
              "      <td>5.919020</td>\n",
              "      <td>7.477165</td>\n",
              "      <td>6.991657</td>\n",
              "      <td>7.947168</td>\n",
              "      <td>5.187158</td>\n",
              "      <td>4.593762</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5199</th>\n",
              "      <td>8.457994</td>\n",
              "      <td>2.114113</td>\n",
              "      <td>8.863459</td>\n",
              "      <td>6.666234</td>\n",
              "      <td>8.863459</td>\n",
              "      <td>7.947168</td>\n",
              "      <td>2.183860</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5200 rows × 46 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            1         2         3         4         5   ...   42   43   44   45   46\n",
              "0     8.863459  2.114113  8.863459  7.477165  8.863459  ...  0.0  0.0  0.0  0.0  0.0\n",
              "1     6.560874  6.560874  6.917549  5.187158  6.378552  ...  0.0  0.0  0.0  0.0  0.0\n",
              "2     5.024007  6.991657  6.723393  7.254021  5.727965  ...  0.0  0.0  0.0  0.0  0.0\n",
              "3     6.337730  7.158711  7.947168  8.170312  2.114113  ...  0.0  0.0  0.0  0.0  0.0\n",
              "4     7.477165  8.863459  8.457994  6.337730  4.820408  ...  0.0  0.0  0.0  0.0  0.0\n",
              "...        ...       ...       ...       ...       ...  ...  ...  ...  ...  ...  ...\n",
              "5195  8.863459  6.001258  8.863459  6.723393  2.114113  ...  0.0  0.0  0.0  0.0  0.0\n",
              "5196  7.158711  5.706459  6.512084  5.397723  8.170312  ...  0.0  0.0  0.0  0.0  0.0\n",
              "5197  5.945688  8.863459  6.784017  2.114113  8.170312  ...  0.0  0.0  0.0  0.0  0.0\n",
              "5198  5.919020  7.477165  6.991657  7.947168  5.187158  ...  0.0  0.0  0.0  0.0  0.0\n",
              "5199  8.457994  2.114113  8.863459  6.666234  8.863459  ...  0.0  0.0  0.0  0.0  0.0\n",
              "\n",
              "[5200 rows x 46 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75ZutRFJP-9d"
      },
      "source": [
        "test_array = df_test[0:].to_numpy()             ##This is the array upon which predictions will be done.\n",
        "y = train.label.to_numpy()             ##This again reassigns the value of y because it was altered in previous segments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojUGg7f0DJpO",
        "outputId": "dbf342bf-c1df-4151-f9b9-14950b537794"
      },
      "source": [
        "svc = SVC(C = 100, kernel = 'rbf', gamma = 0.01, degree = 3)\n",
        "svc.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktBXs7VshZ3A"
      },
      "source": [
        "predicted = svc.predict(test_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hveKet2lDx0"
      },
      "source": [
        "ans = pd.read_csv('/content/gdrive/MyDrive/Submission.csv')\n",
        "solution = ans['label'].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1bcBgxRluZA",
        "outputId": "4ba2ee22-f790-4049-f0c5-0a4571efd150"
      },
      "source": [
        "print(accuracy_score(predicted, solution))\n",
        "print(precision_score(predicted, solution))\n",
        "print(confusion_matrix(predicted, solution))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.78\n",
            "0.7407550077041603\n",
            "[[2133  673]\n",
            " [ 471 1923]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDhb0pV1mLZc",
        "outputId": "b5793e3b-6085-4fe1-c945-53e7db0bf659"
      },
      "source": [
        "kneighbors = KNeighborsClassifier(n_neighbors = 10, weights='distance')\n",
        "kneighbors.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
              "                     weights='distance')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Srqi8las6Xb",
        "outputId": "ececa1a6-8f2e-4913-e95f-b7b43a542ce7"
      },
      "source": [
        "predicted_knn = kneighbors.predict(test_array)\n",
        "print(accuracy_score(predicted_knn, solution))\n",
        "print(precision_score(predicted_knn, solution))\n",
        "print(confusion_matrix(predicted_knn, solution))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7576923076923077\n",
            "0.6648690292758089\n",
            "[[2214  870]\n",
            " [ 390 1726]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EblU3UD-tXd6",
        "outputId": "689f8431-924b-4308-f456-c7b0c56e626d"
      },
      "source": [
        "logreg = LogisticRegression(C = 0.01, penalty = 'l2', solver = 'liblinear', max_iter = 50000, random_state=42, multi_class='ovr')\n",
        "logreg.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=50000,\n",
              "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
              "                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT2Kr57ht3se",
        "outputId": "5ef64dab-cc1c-4a68-d5ba-c345dda319b7"
      },
      "source": [
        "predicted_log = logreg.predict(test_array)\n",
        "print(accuracy_score(predicted_log, solution))\n",
        "print(precision_score(predicted_log, solution))\n",
        "print(confusion_matrix(predicted_log, solution))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6644230769230769\n",
            "0.6024653312788906\n",
            "[[1891 1032]\n",
            " [ 713 1564]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIrNTGwvuEAc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6527bfcd-1557-404d-8a57-a59d0c832b01"
      },
      "source": [
        "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth = 1), algorithm = 'SAMME.R', learning_rate = 1, n_estimators = 250)\n",
        "ada_clf.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(algorithm='SAMME.R',\n",
              "                   base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
              "                                                         class_weight=None,\n",
              "                                                         criterion='gini',\n",
              "                                                         max_depth=1,\n",
              "                                                         max_features=None,\n",
              "                                                         max_leaf_nodes=None,\n",
              "                                                         min_impurity_decrease=0.0,\n",
              "                                                         min_impurity_split=None,\n",
              "                                                         min_samples_leaf=1,\n",
              "                                                         min_samples_split=2,\n",
              "                                                         min_weight_fraction_leaf=0.0,\n",
              "                                                         presort='deprecated',\n",
              "                                                         random_state=None,\n",
              "                                                         splitter='best'),\n",
              "                   learning_rate=1, n_estimators=250, random_state=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLW653nj3514"
      },
      "source": [
        "predicted_adaboost = ada_clf.predict(test_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "votrOyV74BVF",
        "outputId": "b5eebb06-3440-4dd3-ed93-b82a47c34f87"
      },
      "source": [
        "print(accuracy_score(predicted_adaboost, solution))\n",
        "print(precision_score(predicted_adaboost, solution))\n",
        "print(confusion_matrix(predicted_adaboost, solution))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7892307692307692\n",
            "0.6910631741140215\n",
            "[[2310  802]\n",
            " [ 294 1794]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0hajUL5_pKk",
        "outputId": "f921ac35-6de3-4431-c97b-dafe3c4a2e3a"
      },
      "source": [
        "rf_clf = RandomForestClassifier(criterion = 'entropy', max_depth = 24, n_estimators = 300, oob_score=True)\n",
        "rf_clf.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='entropy', max_depth=24, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
              "                       n_jobs=None, oob_score=True, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Cval8bK_sc0",
        "outputId": "24c864f0-3632-46b5-eea4-413198e1141d"
      },
      "source": [
        "predicted_rf = rf_clf.predict(test_array)\n",
        "print(accuracy_score(predicted_rf, solution))\n",
        "print(precision_score(predicted_rf, solution))\n",
        "print(confusion_matrix(predicted_rf, solution))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.815\n",
            "0.7715716486902927\n",
            "[[2235  593]\n",
            " [ 369 2003]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Yz1apliAnAg",
        "outputId": "351cd204-c4b0-475f-e71c-ffd3b697db8b"
      },
      "source": [
        "xgb_clf = XGBClassifier(learning_rate=0.8)\n",
        "xgb_clf.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.8, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGVSVklmAsiz",
        "outputId": "f03f5cfb-592a-4e6a-c131-215904f6409b"
      },
      "source": [
        "predicted_xgb = xgb_clf.predict(test_array)\n",
        "print(accuracy_score(predicted_xgb, solution))\n",
        "print(precision_score(predicted_xgb, solution))\n",
        "print(confusion_matrix(predicted_xgb, solution))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8007692307692308\n",
            "0.7565485362095532\n",
            "[[2200  632]\n",
            " [ 404 1964]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "8Ivf5_JfE9oO",
        "outputId": "2c775f3e-d1db-4edf-eccf-236a231567c3"
      },
      "source": [
        "accuracies = [accuracy_score(predicted, solution), accuracy_score(predicted_knn, solution), accuracy_score(predicted_log, solution), accuracy_score(predicted_adaboost, solution), accuracy_score(predicted_rf, solution), accuracy_score(predicted_xgb, solution)]\n",
        "precisions = [precision_score(predicted, solution), precision_score(predicted_knn, solution), precision_score(predicted_log, solution), precision_score(predicted_adaboost, solution), precision_score(predicted_rf, solution), precision_score(predicted_xgb, solution)]\n",
        "xlabels = ['SVC', 'KNeighborClassifier', 'Logistic Regression', 'Adaboost Classifier', 'RandomForest Classifier', 'XGBoost Classifier']\n",
        "df = pd.DataFrame(zip(accuracies, precisions), columns=['Accuracy', 'Precision'], index=xlabels)\n",
        "df.plot.bar(rot=0, figsize=(15,10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5ec0a25a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLj5lE63IHgV"
      },
      "source": [
        "The precision of KNeighborClassifiers and Logistic Regression are the same.And as always RandomForest Classifiers are the best classifiers of the lot. The next step is to apply Neural Networks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DLrVUCgO7sW"
      },
      "source": [
        "sentence_length = 45\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenizer.fit_on_texts(train['clean_total'])\n",
        "train_total = tokenizer.texts_to_sequences(train['clean_total'])\n",
        "train_total = pad_sequences(train_total,maxlen=sentence_length)\n",
        "test_total = tokenizer.texts_to_sequences(test['clean_total'])\n",
        "test_total = pad_sequences(test_total,maxlen=sentence_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC4ncGclP1pB",
        "outputId": "5c52fc53-5d44-4e43-9448-d0d4dcb2a707"
      },
      "source": [
        "train_total.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20800, 45)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et9I7essQLHC"
      },
      "source": [
        "def create_model(learning_rate):\n",
        "      opt = Adam(lr = learning_rate)\n",
        "      embedding_vector_features=30\n",
        "      model = keras.Sequential()\n",
        "      model.add(layers.Embedding(60000,embedding_vector_features,input_length=sentence_length))\n",
        "      model.add(layers.Dropout(0.3))\n",
        "      model.add(layers.LSTM(50))\n",
        "      model.add(layers.Dropout(0.3))\n",
        "      model.add(layers.Dense(64,activation='relu'))\n",
        "      model.add(layers.Dropout(0.3))\n",
        "      model.add(layers.Dense(1,activation='relu'))\n",
        "      model.compile(loss='binary_crossentropy',optimizer=opt ,metrics=['accuracy'])\n",
        "      return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyaBK_LNQ9lx"
      },
      "source": [
        "model = KerasClassifier(build_fn = create_model)\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor = 'accuracy',\n",
        "    min_delta = 0.1,\n",
        "    patience = 5,\n",
        "    verbose = 0\n",
        ")\n",
        "callbacks = [early_stop]\n",
        "params = {\n",
        "          'learning_rate' : [0.1, 0.01, 0.001],\n",
        "          'batch_size': [64],\n",
        "          'callbacks':callbacks,\n",
        "          'epochs' :[25]\n",
        "          }\n",
        "random_search = RandomizedSearchCV(model, param_distributions=params, cv=KFold(3), n_jobs=1, verbose=1)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='accuracy', factor=0.1, patience=5, verbose=1, mode='min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiDlfnokRlXv"
      },
      "source": [
        "X = train_total\n",
        "y = train['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEWt68MGRpnw",
        "outputId": "65a223b4-d188-44d7-aae5-0ab61a2074c2"
      },
      "source": [
        "random_search.fit(X, y)\n",
        "\n",
        "print('Best score obtained: {0}'.format(random_search.best_score_))\n",
        "print('Parameters:')\n",
        "for param, value in random_search.best_params_.items():\n",
        "    print('\\t{}: {}'.format(param, value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "Epoch 1/25\n",
            "217/217 [==============================] - 20s 80ms/step - loss: 0.7877 - accuracy: 0.4960\n",
            "Epoch 2/25\n",
            "217/217 [==============================] - 17s 80ms/step - loss: 0.6667 - accuracy: 0.5415\n",
            "Epoch 3/25\n",
            "217/217 [==============================] - 17s 79ms/step - loss: 0.6822 - accuracy: 0.6471\n",
            "Epoch 4/25\n",
            "217/217 [==============================] - 18s 81ms/step - loss: 0.7302 - accuracy: 0.6834\n",
            "Epoch 5/25\n",
            "217/217 [==============================] - 18s 82ms/step - loss: 0.7110 - accuracy: 0.6829\n",
            "Epoch 6/25\n",
            "217/217 [==============================] - 17s 79ms/step - loss: 0.5855 - accuracy: 0.7319\n",
            "Epoch 7/25\n",
            "217/217 [==============================] - 17s 81ms/step - loss: 0.5454 - accuracy: 0.7484\n",
            "Epoch 8/25\n",
            "217/217 [==============================] - 17s 80ms/step - loss: 0.5348 - accuracy: 0.7545\n",
            "Epoch 9/25\n",
            "217/217 [==============================] - 17s 80ms/step - loss: 0.5135 - accuracy: 0.7726\n",
            "Epoch 10/25\n",
            "217/217 [==============================] - 17s 80ms/step - loss: 0.4904 - accuracy: 0.7740\n",
            "Epoch 11/25\n",
            "217/217 [==============================] - 17s 80ms/step - loss: 0.4935 - accuracy: 0.7839\n",
            "Epoch 12/25\n",
            "217/217 [==============================] - 18s 81ms/step - loss: 0.4877 - accuracy: 0.7899\n",
            "109/109 [==============================] - 3s 20ms/step - loss: 0.3104 - accuracy: 0.8525\n",
            "Epoch 1/25\n",
            "217/217 [==============================] - 20s 83ms/step - loss: 0.4487 - accuracy: 0.8078\n",
            "Epoch 2/25\n",
            "217/217 [==============================] - 18s 84ms/step - loss: 0.2695 - accuracy: 0.9306\n",
            "Epoch 3/25\n",
            "217/217 [==============================] - 18s 84ms/step - loss: 0.3912 - accuracy: 0.8968\n",
            "Epoch 4/25\n",
            "217/217 [==============================] - 18s 85ms/step - loss: 0.5338 - accuracy: 0.8566\n",
            "Epoch 5/25\n",
            "217/217 [==============================] - 18s 83ms/step - loss: 0.4746 - accuracy: 0.8502\n",
            "Epoch 6/25\n",
            "217/217 [==============================] - 18s 82ms/step - loss: 0.4003 - accuracy: 0.8659\n",
            "Epoch 7/25\n",
            "217/217 [==============================] - 18s 83ms/step - loss: 0.4323 - accuracy: 0.8582\n",
            "109/109 [==============================] - 3s 19ms/step - loss: 0.3054 - accuracy: 0.8559\n",
            "Epoch 1/25\n",
            "217/217 [==============================] - 20s 83ms/step - loss: 0.7698 - accuracy: 0.5709\n",
            "Epoch 2/25\n",
            "217/217 [==============================] - 18s 83ms/step - loss: 0.7090 - accuracy: 0.7746\n",
            "Epoch 3/25\n",
            "217/217 [==============================] - 18s 83ms/step - loss: 0.4100 - accuracy: 0.8513\n",
            "Epoch 4/25\n",
            "217/217 [==============================] - 18s 83ms/step - loss: 0.3704 - accuracy: 0.8681\n",
            "Epoch 5/25\n",
            "217/217 [==============================] - 18s 82ms/step - loss: 0.3689 - accuracy: 0.8724\n",
            "Epoch 6/25\n",
            "217/217 [==============================] - 18s 81ms/step - loss: 0.3220 - accuracy: 0.8889\n",
            "Epoch 7/25\n",
            "217/217 [==============================] - 17s 80ms/step - loss: 0.3447 - accuracy: 0.8869\n",
            "Epoch 8/25\n",
            "217/217 [==============================] - 18s 82ms/step - loss: 0.3164 - accuracy: 0.8931\n",
            "Epoch 9/25\n",
            "217/217 [==============================] - 18s 83ms/step - loss: 0.3171 - accuracy: 0.8892\n",
            "Epoch 10/25\n",
            "217/217 [==============================] - 18s 82ms/step - loss: 0.2967 - accuracy: 0.8933\n",
            "Epoch 11/25\n",
            "217/217 [==============================] - 18s 81ms/step - loss: 0.2966 - accuracy: 0.8806\n",
            "109/109 [==============================] - 3s 19ms/step - loss: 0.4271 - accuracy: 0.8979\n",
            "Epoch 1/25\n",
            "217/217 [==============================] - 19s 79ms/step - loss: 0.1038 - accuracy: 0.9555\n",
            "Epoch 2/25\n",
            "217/217 [==============================] - 17s 79ms/step - loss: 0.0092 - accuracy: 0.9975\n",
            "Epoch 3/25\n",
            "217/217 [==============================] - 18s 81ms/step - loss: 0.0012 - accuracy: 0.9996\n",
            "Epoch 4/25\n",
            "217/217 [==============================] - 17s 79ms/step - loss: 2.4596e-04 - accuracy: 1.0000\n",
            "Epoch 5/25\n",
            "217/217 [==============================] - 17s 78ms/step - loss: 5.2356e-05 - accuracy: 1.0000\n",
            "Epoch 6/25\n",
            "217/217 [==============================] - 17s 78ms/step - loss: 9.0614e-04 - accuracy: 0.9999\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.0635 - accuracy: 0.9860\n",
            "Epoch 1/25\n",
            "217/217 [==============================] - 19s 78ms/step - loss: 0.1083 - accuracy: 0.9573\n",
            "Epoch 2/25\n",
            "217/217 [==============================] - 17s 78ms/step - loss: 0.0057 - accuracy: 0.9984\n",
            "Epoch 3/25\n",
            "217/217 [==============================] - 17s 78ms/step - loss: 0.0012 - accuracy: 0.9994\n",
            "Epoch 4/25\n",
            "217/217 [==============================] - 17s 78ms/step - loss: 1.5836e-04 - accuracy: 0.9999\n",
            "Epoch 5/25\n",
            "217/217 [==============================] - 17s 79ms/step - loss: 3.1193e-05 - accuracy: 1.0000\n",
            "Epoch 6/25\n",
            "217/217 [==============================] - 17s 79ms/step - loss: 2.3980e-05 - accuracy: 1.0000\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.0698 - accuracy: 0.9895\n",
            "Epoch 1/25\n",
            "217/217 [==============================] - 19s 79ms/step - loss: 0.1043 - accuracy: 0.9606\n",
            "Epoch 2/25\n",
            "217/217 [==============================] - 17s 78ms/step - loss: 0.0063 - accuracy: 0.9980\n",
            "Epoch 3/25\n",
            "217/217 [==============================] - 17s 79ms/step - loss: 0.0022 - accuracy: 0.9995\n",
            "Epoch 4/25\n",
            "217/217 [==============================] - 17s 79ms/step - loss: 0.0018 - accuracy: 0.9996\n",
            "Epoch 5/25\n",
            "217/217 [==============================] - 17s 79ms/step - loss: 0.0023 - accuracy: 0.9992\n",
            "Epoch 6/25\n",
            "217/217 [==============================] - 17s 80ms/step - loss: 0.0017 - accuracy: 0.9996\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.1199 - accuracy: 0.9814\n",
            "Epoch 1/25\n",
            "217/217 [==============================] - 19s 80ms/step - loss: 0.2434 - accuracy: 0.8877\n",
            "Epoch 2/25\n",
            "217/217 [==============================] - 17s 80ms/step - loss: 0.0177 - accuracy: 0.9944\n",
            "Epoch 3/25\n",
            "217/217 [==============================] - 17s 80ms/step - loss: 0.0051 - accuracy: 0.9986\n",
            "Epoch 4/25\n",
            "217/217 [==============================] - 17s 80ms/step - loss: 0.0012 - accuracy: 0.9996\n",
            "Epoch 5/25\n",
            "217/217 [==============================] - 17s 80ms/step - loss: 4.5251e-04 - accuracy: 0.9999\n",
            "Epoch 6/25\n",
            "217/217 [==============================] - 17s 80ms/step - loss: 2.7484e-04 - accuracy: 0.9999\n",
            "Epoch 7/25\n",
            "217/217 [==============================] - 17s 81ms/step - loss: 1.6561e-04 - accuracy: 1.0000\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.0442 - accuracy: 0.9877\n",
            "Epoch 1/25\n",
            "217/217 [==============================] - 19s 81ms/step - loss: 0.2372 - accuracy: 0.8953\n",
            "Epoch 2/25\n",
            "217/217 [==============================] - 17s 80ms/step - loss: 0.0182 - accuracy: 0.9944\n",
            "Epoch 3/25\n",
            "217/217 [==============================] - 17s 80ms/step - loss: 0.0031 - accuracy: 0.9992\n",
            "Epoch 4/25\n",
            "217/217 [==============================] - 17s 80ms/step - loss: 9.2950e-04 - accuracy: 0.9997\n",
            "Epoch 5/25\n",
            "217/217 [==============================] - 17s 81ms/step - loss: 5.4984e-04 - accuracy: 0.9999\n",
            "Epoch 6/25\n",
            "217/217 [==============================] - 18s 81ms/step - loss: 2.6597e-04 - accuracy: 0.9999\n",
            "Epoch 7/25\n",
            "217/217 [==============================] - 18s 81ms/step - loss: 8.2585e-05 - accuracy: 1.0000\n",
            "Epoch 8/25\n",
            "217/217 [==============================] - 17s 80ms/step - loss: 4.7078e-04 - accuracy: 0.9999\n",
            "109/109 [==============================] - 2s 18ms/step - loss: 0.0410 - accuracy: 0.9911\n",
            "Epoch 1/25\n",
            "217/217 [==============================] - 19s 80ms/step - loss: 0.2262 - accuracy: 0.9040\n",
            "Epoch 2/25\n",
            "217/217 [==============================] - 17s 80ms/step - loss: 0.0173 - accuracy: 0.9950\n",
            "Epoch 3/25\n",
            "217/217 [==============================] - 18s 81ms/step - loss: 0.0031 - accuracy: 0.9992\n",
            "Epoch 4/25\n",
            "217/217 [==============================] - 17s 80ms/step - loss: 0.0015 - accuracy: 0.9996\n",
            "Epoch 5/25\n",
            "217/217 [==============================] - 17s 81ms/step - loss: 6.1513e-04 - accuracy: 0.9999\n",
            "Epoch 6/25\n",
            "217/217 [==============================] - 18s 81ms/step - loss: 9.0400e-04 - accuracy: 0.9997\n",
            "109/109 [==============================] - 3s 19ms/step - loss: 0.0446 - accuracy: 0.9893\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 23.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "325/325 [==============================] - 26s 73ms/step - loss: 0.1602 - accuracy: 0.9337\n",
            "Epoch 2/25\n",
            "325/325 [==============================] - 24s 73ms/step - loss: 0.0124 - accuracy: 0.9961\n",
            "Epoch 3/25\n",
            "325/325 [==============================] - 24s 73ms/step - loss: 0.0026 - accuracy: 0.9992\n",
            "Epoch 4/25\n",
            "325/325 [==============================] - 24s 73ms/step - loss: 9.9023e-04 - accuracy: 0.9998\n",
            "Epoch 5/25\n",
            "325/325 [==============================] - 24s 73ms/step - loss: 2.9012e-04 - accuracy: 1.0000\n",
            "Epoch 6/25\n",
            "325/325 [==============================] - 24s 73ms/step - loss: 4.5439e-04 - accuracy: 0.9999\n",
            "Best score obtained: 0.989375094572703\n",
            "Parameters:\n",
            "\tlearning_rate: 0.001\n",
            "\tepochs: 25\n",
            "\tcallbacks: <tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f1c6f50e9d0>\n",
            "\tbatch_size: 64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR8S1mcSYMqb"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUlt0eNlY8Zn"
      },
      "source": [
        "    opt = Adam(learning_rate=0.001)\n",
        "    embedding_vector_features=40\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Embedding(60000,embedding_vector_features,input_length=sentence_length))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.LSTM(50))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Dense(64,activation='relu'))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Dense(1,activation='relu'))\n",
        "    model.compile(loss='binary_crossentropy',optimizer=opt ,metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJDqgqTSZBGG",
        "outputId": "9ac512c1-d878-4fe4-acc6-ebb11fc69567"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_test,y_test),\n",
        "                    callbacks=[early_stop,reduce_lr],\n",
        "                    epochs = 50,\n",
        "                    batch_size = 64\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "218/218 [==============================] - 16s 63ms/step - loss: 0.5666 - accuracy: 0.7880 - val_loss: 0.1008 - val_accuracy: 0.9722\n",
            "Epoch 2/50\n",
            "218/218 [==============================] - 14s 62ms/step - loss: 0.1478 - accuracy: 0.9427 - val_loss: 0.1536 - val_accuracy: 0.9318\n",
            "Epoch 3/50\n",
            "218/218 [==============================] - 13s 61ms/step - loss: 0.0373 - accuracy: 0.9921 - val_loss: 0.0593 - val_accuracy: 0.9894\n",
            "Epoch 4/50\n",
            "218/218 [==============================] - 13s 62ms/step - loss: 0.0205 - accuracy: 0.9971 - val_loss: 0.0590 - val_accuracy: 0.9910\n",
            "Epoch 5/50\n",
            "218/218 [==============================] - 13s 61ms/step - loss: 0.0113 - accuracy: 0.9986 - val_loss: 0.0579 - val_accuracy: 0.9910\n",
            "Epoch 6/50\n",
            "218/218 [==============================] - 13s 61ms/step - loss: 0.0174 - accuracy: 0.9958 - val_loss: 0.0712 - val_accuracy: 0.9837\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 7/50\n",
            "218/218 [==============================] - 13s 61ms/step - loss: 0.0126 - accuracy: 0.9986 - val_loss: 0.0594 - val_accuracy: 0.9872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "vrrVbbgnl_EJ",
        "outputId": "628b29fa-c84e-4e99-f6fa-694c2408d328"
      },
      "source": [
        "history_df = pd.DataFrame(history.history)\n",
        "history_df.loc[:,['val_loss', 'loss']].plot()\n",
        "print(\"Minimum Loss: {}\".format(history_df['loss'].min()))\n",
        "print(\"Minimum Validation Loss: {}\".format(history_df['val_loss'].min()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum Loss: 0.011321472935378551\n",
            "Minimum Validation Loss: 0.05785120278596878\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MAcN6gOaJtS"
      },
      "source": [
        "pred = model.predict(X_test)\n",
        "pred = pred.reshape(-1)\n",
        "pred.tolist()\n",
        "pred = [1 if x > 0.5 else 0 for x in pred]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q-paC15aTLX",
        "outputId": "1f2387d6-1754-44e9-9b76-49c95b8bf7d8"
      },
      "source": [
        "target_names = ['label_0', 'label_1']\n",
        "print(classification_report(pred, y_test, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     label_0       0.99      0.98      0.99      3489\n",
            "     label_1       0.98      0.99      0.99      3375\n",
            "\n",
            "    accuracy                           0.99      6864\n",
            "   macro avg       0.99      0.99      0.99      6864\n",
            "weighted avg       0.99      0.99      0.99      6864\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX1y_SpTaotx",
        "outputId": "7a06fd35-0246-4158-dcc8-39ddbeaae87e"
      },
      "source": [
        "test_pred = model.predict(test_total)\n",
        "test_pred = test_pred.reshape(-1)\n",
        "test_pred.tolist()\n",
        "test_pred = [1 if x > 0.5 else 0 for x in test_pred]\n",
        "target_names = ['label_0', 'label_1']\n",
        "print(classification_report(test_pred, solution, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     label_0       0.99      0.99      0.99      2616\n",
            "     label_1       0.99      0.99      0.99      2584\n",
            "\n",
            "    accuracy                           0.99      5200\n",
            "   macro avg       0.99      0.99      0.99      5200\n",
            "weighted avg       0.99      0.99      0.99      5200\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB0Nj2KXbClM",
        "outputId": "eaca3ab5-ae73-4e3c-9390-2d1991795848"
      },
      "source": [
        "print(accuracy_score(test_pred, solution))\n",
        "print(precision_score(test_pred, solution))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9911538461538462\n",
            "0.9888289676425269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5QDPHWa63fN",
        "outputId": "19dc1e66-31af-43dc-f98c-07ed0ea6893d"
      },
      "source": [
        "new = input(\"Enter the headline of the news article along with the author name: \")\n",
        "new_stemmed = porterstemmer(new)\n",
        "new_df = pd.Series(new_stemmed)\n",
        "tokenizer.fit_on_texts(new_df)\n",
        "new_total = tokenizer.texts_to_sequences(new_df)\n",
        "new_total = pad_sequences(new_total, maxlen=sentence_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the headline of the news article along with the author name: I don't know what to do. -The HinduRidhi Thalaseima\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv8am3U9E0V4",
        "outputId": "c1f8433c-75f1-49f2-f61b-d0f656446d55"
      },
      "source": [
        "x = model.predict(new_total)\n",
        "if x > 0.5:\n",
        "  x = 1\n",
        "else:\n",
        "  x = 0\n",
        "\n",
        "print(\"The news source is {}\".format(\"unreliable\" if x==1 else \"reliable\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The news source is unreliable\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHzfsVsdGgrn",
        "outputId": "62e21d55-5063-4869-9eaa-7aedbef09506"
      },
      "source": [
        "model.predict(new_total)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.8478582]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    }
  ]
}